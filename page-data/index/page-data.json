{"componentChunkName":"component---src-pages-index-jsx","path":"/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"✋ 들어가며  시리즈의 첫번째 포스팅이다.\n티스토리, 네이버 블로그 등에서는 당연히 있고 없으면 안되는 부가 기능 중에 하나가 가 아닐까? 일반적인 블로그 처럼 접속하면 바로 보이는 총 방문자, 오늘 방문자가 필자와 같이 등을 이용해서 운영하는 블로그에도 표시되면 좋겠다는 생각으로 이 시리즈를 시작하게 되었다. 사실 이미 만들어져있는 상태로 게시글을 쓰고…","fields":{"slug":"/free-visitor-counter-01-requirements/"},"frontmatter":{"date":"April 26, 2025","title":"블로그/홈페이지 방문자 카운터 무료 배포를 위한 요구사항 분석","tags":["visitorcounter","opensource","free","blog"],"emoji":"☝️","series":"📊 블로그/홈페이지 방문자 카운터 무료 배포하기"},"rawMarkdownBody":"\n## ✋ 들어가며\n`웹사이트용 방문자 카운터 무료 배포하기` 시리즈의 첫번째 포스팅이다.\n티스토리, 네이버 블로그 등에서는 당연히 있고 없으면 안되는 부가 기능 중에 하나가 `방문자 카운터`가 아닐까?\n\n일반적인 블로그 처럼 접속하면 바로 보이는 *총 방문자, 오늘 방문자*가 필자와 같이 `Github Pages`등을 이용해서 운영하는 블로그에도 표시되면 좋겠다는 생각으로 이 시리즈를 시작하게 되었다.\n\n사실 이미 만들어져있는 상태로 게시글을 쓰고있기 때문에 완성된 모습은\n필자가 제작한 [Gatsby 테마 README](http://github.com/rundevelrun/gatsby-starter-rundevelrun)를 살펴보면 자세한 내용을 볼 수 있다.\n\n## 📋 요구사항을 분석해보자\n\n### 기능 요구사항 (Functional Requirements)\n\n#### ***백엔드 (API 서버)***\n\n| ID    | 기능명           | 설명 |\n|:------|:--------------|:---|\n| FR-01 | 방문자 기록 API 제공 | 웹사이트 접속 시 방문자 데이터를 기록한다. |\n| FR-02 | 중복 방문 방지      | Redis를 이용하여 20분 이내 재접속 시 중복 카운트 방지한다. |\n| FR-03 | 대시보드 제공       | 기간별 방문자 수, 리퍼러, 검색어 등을 시각화하여 보여준다. |\n| FR-04 | API 문서 제공     | API 명세를 제공하여 외부 시스템 연동이 가능하도록 지원한다. |\n| FR-05 | 다국어 지원        | 대시보드 페이지는 영어, 한국어, 일본어를 지원한다. |\n| FR-06 | 다크/라이트 테마 지원  | 사용자 브라우저 설정에 따라 테마를 자동 적용한다. |\n\n#### ***프론트엔드 (React 컴포넌트)***\n\n| ID    | 기능명 | 설명 |\n|:------|:---|:---|\n| FR-07 | 방문자 수 표시 | 총 방문자 수 및 오늘 방문자 수를 표시한다. |\n| FR-08 | 스타일 커스터마이징 | 표시 텍스트, 구분자, 스타일 등을 커스터마이징할 수 있다. |\n| FR-09 | 비동기 호출 및 데이터 갱신 | API 호출 결과를 받아 비동기적으로 렌더링한다. |\n\n---\n\n### 비기능 요구사항 (Non-Functional Requirements)\n\n| ID | 항목 | 설명 |\n|:---|:---|:---|\n| NFR-01 | 무료 배포 | 시스템은 누구나 무료로 사용할 수 있어야 한다. |\n| NFR-02 | 소스코드 공개 | 소스코드는 GitHub에 공개하며, MIT 라이선스를 적용한다. |\n| NFR-03 | 경량화된 구성 | 빠른 로딩을 위해 API 서버와 React 컴포넌트는 경량화되어야 한다. |\n| NFR-04 | 반응형 UI 지원 | 대시보드는 PC, 태블릿, 모바일에서도 잘 작동해야 한다. |\n| NFR-05 | 데이터베이스 안정성 | PostgreSQL을 사용하여 방문자 기록을 안정적으로 저장한다. |\n| NFR-06 | 서버 보안 | 모든 API 호출은 HTTPS를 통해 이루어져야 한다. |\n| NFR-07 | NPM 패키지 배포 | React 방문자 카운터 컴포넌트는 NPM Public Registry에 배포하여 누구나 설치할 수 있어야 한다. |\n| NFR-08 | 형상 관리 | 프로젝트는 GitHub를 통해 형상 관리 및 버전 관리가 이루어져야 한다. |\n\n---\n\n### 운영 및 배포 요구사항 (Deployment & Operations Requirements)\n\n| ID | 항목 | 설명 |\n|:---|:---|:---|\n| DOR-01 | 배포 환경 | 백엔드 서버는 cPanel 기반 환경에서 Passenger WSGI를 이용해 구동되어야 한다. |\n| DOR-02 | 데이터베이스 연결 | PostgreSQL 데이터베이스와 연결하여 방문자 데이터를 저장해야 한다. |\n| DOR-03 | Redis 연결 | 방문자 중복 처리를 위해 Redis 서버가 설치 및 연결되어야 한다. |\n| DOR-04 | 환경 변수 관리 | `.env` 파일을 통해 데이터베이스, Redis, 보안 키 등 환경 설정을 관리해야 한다. |\n| DOR-05 | HTTPS 지원 | 운영 서버는 반드시 SSL 인증서를 적용하여 HTTPS 통신을 지원해야 한다. |\n| DOR-06 | 서버 사이드 렌더링 (SSR) | 대시보드 및 웹페이지는 Flask + Jinja 템플릿 엔진을 사용하여 서버 사이드 렌더링 방식으로 제공되어야 한다. |\n| DOR-07 | 다국어 및 테마 대응 | 대시보드는 브라우저 설정에 따라 다국어 및 다크/라이트 테마를 자동 적용해야 한다. |\n| DOR-08 | 유지보수 편의성 | 코드 및 환경 설정은 cPanel 환경에서도 수정과 유지보수가 용이하도록 구성되어야 한다. |\n| DOR-09 | NPM 패키지 유지관리 | 배포된 NPM 패키지는 주기적으로 업데이트 및 유지보수되어야 한다. |\n| DOR-10 | GitHub 관리 | 모든 소스코드 변경사항은 GitHub 저장소를 통해 관리하고, 이슈/PR 기반으로 개발 프로세스를 유지해야 한다. |\n\n\n## 👋 마치며\n이 시리즈에서는 **Flask 백엔드 API + React 컴포넌트** 조합으로\n누구나 쉽게 설치할 수 있는 방문자 카운터를 만들어 배포하는 과정을 다룰 예정인데 무료로 배포하는 만큼 많은 사람들이 사용할 수 있으면 좋겠다."},{"excerpt":"☀️ 테스트 환경 OpenJDK 17.0.2 Spring Boot 3.0.5 ✋ 들어가며 JWT를 구현하는 중에 내장 톰캣이 시작되지 못했다는 아주 기분나쁜 에러를 만났다. , \n필자가 겪은 문제는 JWT Filter와 AOP의 조합에서 문제가 생겼는데 오류의 원인과 해결방법을 공유하보려고 한다. ‼️ 문제의 재구성 실제로 겪었던 문제를 다시 살펴보기 위해서…","fields":{"slug":"/spring-jwt-aop-log-null-error/"},"frontmatter":{"date":"April 06, 2025","title":"Spring AOP + JWT logger is null 수정","tags":["spring","springboot","aop","jwt","error"],"emoji":"🧨","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - OpenJDK 17.0.2\n> - Spring Boot 3.0.5\n\n\n## ✋ 들어가며\nJWT를 구현하는 중에 내장 톰캣이 시작되지 못했다는 아주 기분나쁜 에러를 만났다. `\"this.logger\" is null`, `Unable to start embedded Tomcat`\n필자가 겪은 문제는 JWT Filter와 AOP의 조합에서 문제가 생겼는데 오류의 원인과 해결방법을 공유하보려고 한다.\n---\n\n## ‼️ 문제의 재구성\n실제로 겪었던 문제를 다시 살펴보기 위해서 아래와 같은 문제의 소스를 다시 만들어봤다.\nAOP에서는 `PointCut`의 범위를 `JwtAuthenticationFilter`까지 포함할 수 있도록 패키지내 모든 클래스에 진입할때 로그가 발생하도록 작성했다. (이유를 알고 봐도 크게 문제가 없어보인다.)\n\n#### ***문제의 소스코드***\n\n1. Spring Security에서 JWT 토큰 인증을 위한 필터. `OncePerRequestFilter`를 상속\n    ```java\n    @Slf4j\n    public class JwtAuthenticationFilter extends OncePerRequestFilter {\n        private final JwtUtil jwtUtil;\n        private final UserDetailsService userDetailsService;\n    ...\n    ```\n\n2. 패키지내 클래스에 진입할 때 로그를 찍는 AOP\n    ```java\n    @Pointcut(\"execution(* com.sample..*(..))\")\n    public void logPointcut() {}\n    \n    @Before(\"logPointcut()\")\n    public void doLog(JoinPoint joinPoint) {\n        log.debug(\"[ENTER] \" + joinPoint.getSignature());\n    }\n    ...\n    ```\n\n#### ***에러 내용***\n- 실행하면 내장 톰캣이 올라오지 않고 아래와 같은 에러가 발생한다. 다시 봐도 기분이 몹시 나쁘다. `\"this.logger\" is null`, `Unable to start embedded Tomcat`\n    ```java\n    Cannot invoke \"org.apache.commons.logging.Log.isDebugEnabled()\" because \"this.logger\" is null\n    \n    Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.commons.logging.Log.isDebugEnabled()\" because \"this.logger\" is null\n        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109)\n        at com.sample.security.filter.JwtAuthenticationFilter.doFilterInternal(JwtAuthenticationFilter.java:42)\n        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:209)\n        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:178)\n    \n    Caused by: org.springframework.context.ApplicationContextException: Unable to start web server\n        at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:164)\n    \n    Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat\n        at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:142)\n    ```\n---\n\n## ❓왓 더 Logger가 왜 Null인데\n\nSpring Security + JWT + AOP 조합에서 `JwtAuthenticationFilter`가 AOP `PointCut`의 범위에 포함되는 순간 에러가 발생한다.\n\n- Spring AOP는 메서드를 가로채기 위해 프록시 객체를 생성한다.\n- AOP는 클래스의 메서드만 프록시로 감싸고, 필드는 복제하지 않는다.\n- `JwtAuthenticationFilter`에서 상속받고 있는 `OncePerRequestFilter` 클래스에는 ```if (logger.isDebugEnabled()) {``` 구문이 존재한다.\n- 필드는 복제되지 않기 때문에 `logger.isDebugEnabled()` 호출 시 `\"this.logger\" is null`\n- 결국 내장 톰캣은 실행되지 못하고 `Unable to start embedded Tomcat`을 내뱉는다.\n\n---\n\n## ✅ 해결: AOP Pointcut에서 필터 제외시키기\n\nAOP 대상에서 `JwtAuthenticationFilter`를 명시적으로 제외시켜주는걸로 톰캣이 다시 살아났다.\n\n```java\n@Pointcut(\n        \"(execution(* com.sample..*(..)))\" \n        + \" && !within(com.sample.security.filter.JwtAuthenticationFilter)\"\n)\npublic void logPointcut() {}\n\n    @Before(\"logPointcut()\")\n    public void doLog(JoinPoint joinPoint) {\n        log.debug(\"[ENTER] \" + joinPoint.getSignature());\n    }\n    ...\n```\n\n---\n\n## 👋 마치며\n로컬 환경에서도 로그 레벨을 `error`로 해두고 개발을 하다가 콘솔에  \n`[Cannot invoke... is null]`이 찍히지 않아서 문제를 정확하게 파악하지 못하고 있었다.\n옆자리 은인에게 도움을 받아서 해결.. (결국 로그 레벨의 중요성을 이제야 깨달은 멍청한 나의 탓)"},{"excerpt":"☀️ 테스트 환경 OpenJDK 17.0.2 Gradle 8.0.2 Spring Boot 3.0.5 ✋ 들어가며 API 권한 관리 화면을 만들기 위해서 전체 API의 전체 목록을 조회해야 하는 상황이 생겨버렸다. 첫번째로 생각했던 방법은 프로젝트에 설정되어있는 스웨거 화면을 크롤링하는 것이었는데 스웨거가 없는 환경에서도 언젠가 활용할지도 모른다는 생각에 이…","fields":{"slug":"/spring-get-api-list/"},"frontmatter":{"date":"April 03, 2025","title":"Spring Annotation 값 읽기 (API 전체 목록 조회)","tags":["spring","springboot","annotation"],"emoji":"📖","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - OpenJDK 17.0.2\n> - Gradle 8.0.2\n> - Spring Boot 3.0.5\n\n## ✋ 들어가며\nAPI 권한 관리 화면을 만들기 위해서 전체 API의 전체 목록을 조회해야 하는 상황이 생겨버렸다.\n\n첫번째로 생각했던 방법은 프로젝트에 설정되어있는 스웨거 화면을 크롤링하는 것이었는데 스웨거가 없는 환경에서도 언젠가 활용할지도 모른다는 생각에 이 포스팅의 목적인 두번째 아이디어를 실행하기로 했다.\n\n## 💡 아이디어\n\n#### ***API가 구성된 패턴***\n내가 뽑아와야할 API는 주소와 메소드를 확인할 수 있도록 아래와 같은 형태로 구성이 되어있다.\n```java\n@RequestMapping(\"/api\")\npublic class SampleController {\n   @GetMapping(value = \"/v1/get\", produces = MediaType.APPLICATION_JSON_VALUE)\n   public ... {}\n    \n   @PostMapping(value = \"/v1/post\", produces = MediaType.APPLICATION_JSON_VALUE)\n   public ... {}\n   \n   @PutMapping(value = \"/v1/put\", produces = MediaType.APPLICATION_JSON_VALUE)\n   public ... {}\n    \n   @DeleteMapping(value = \"/v1/delete\", produces = MediaType.APPLICATION_JSON_VALUE)\n   public ... {}\n}\n```\n\n#### ***만들어내고 싶은 데이터의 모습***\n\n| className                   | apiUrl         | httpMethod |\n|-----------------------------|----------------|------------|\n| com.sample.SampleController | /api/vi/get    | GET        |\n| com.sample.SampleController | /api/vi/post   | POST       |\n| com.sample.SampleController | /api/vi/delete | DELETE     |\n| com.sample.SampleController | /api/vi/put    | PUT        |\n\n#### ***그래서 어떻게 만들건데?***\n패키지내 모든 클래스와 메소드를 순회하면서\n`@RequestMapping`, `@GetMapping`, `@PostMapping`, `@DeleteMapping`, `@PutMapping`에 포함된 값을 읽어오는 클래스를 만들어보자\n\n\n## 💿 실현된 아이디어\n설명을 좀 해보려고 했는데 `com.sample` 패키지 내 모든 컨트롤러 또 컨트롤러 하위에 있는 메소드들을 모두 스캔하면서\nAnnotation의 값을 읽어오는게 전부라 별로 할말이 없다.\n\n```java\npackage com.sample;\n\nimport io.swagger.v3.oas.annotations.Operation;\nimport org.springframework.beans.factory.config.BeanDefinition;\nimport org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider;\nimport org.springframework.core.type.filter.AnnotationTypeFilter;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.util.ClassUtils;\nimport org.springframework.web.bind.annotation.*;\n\nimport java.util.Set;\n\npublic class APIFinder {\n    public static void main(String[] args) {\n        ClassPathScanningCandidateComponentProvider provider = new ClassPathScanningCandidateComponentProvider(false);\n        provider.addIncludeFilter(new AnnotationTypeFilter(Controller.class));\n\n        Set<BeanDefinition> controllerBeans = provider.findCandidateComponents(\"com.sample\");\n\n        for (BeanDefinition beanDefinition : controllerBeans) {\n            String className = beanDefinition.getBeanClassName();\n            Class<?> clazz = ClassUtils.resolveClassName(className, ClassUtils.getDefaultClassLoader());\n\n            RequestMapping requestMapping = clazz.getAnnotation(RequestMapping.class);\n            String prefix = requestMapping.value()[0];\n\n            for (java.lang.reflect.Method method : clazz.getMethods()) {\n                GetMapping getMapping = method.getAnnotation(GetMapping.class);\n                PostMapping postMapping = method.getAnnotation(PostMapping.class);\n                PutMapping putMapping = method.getAnnotation(PutMapping.class);\n                DeleteMapping deleteMapping = method.getAnnotation(DeleteMapping.class);\n\n                String mapping = \"\";\n                String methodStr = \"\";\n                \n                if(getMapping != null){\n                    methodStr = \"GET\";\n                    String [] arr = method.getAnnotation(GetMapping.class).value();\n                    if(arr.length != 0){\n                        mapping = arr[0];\n                    }\n                }else if(postMapping != null){\n                    methodStr = \"POST\";\n                    String [] arr = method.getAnnotation(PostMapping.class).value();\n                    if(arr.length != 0){\n                        mapping = arr[0];\n                    }\n                }else if(putMapping != null){\n                    methodStr = \"PUT\";\n                    String [] arr = method.getAnnotation(PutMapping.class).value();\n                    if(arr.length != 0){\n                        mapping = arr[0];\n                    }\n                }else if(deleteMapping != null){\n                    methodStr = \"DELETE\";\n                    String [] arr = method.getAnnotation(DeleteMapping.class).value();\n                    if(arr.length != 0){\n                        mapping = arr[0];\n                    }\n                }\n                if(!methodStr.equals(\"\")){\n                    System.out.println(className + \"\\t\" + prefix + mapping + \"\\t\" + methodStr);\n                }\n            }\n        }\n    }\n}\n```\n\n```shell\n✔\ncom.sample.SampleController   /api/vi/get       GET\ncom.sample.SampleController   /api/vi/post      POST\ncom.sample.SampleController   /api/vi/delete    DELETE\ncom.sample.SampleController   /api/vi/put       PUT\n```\n\n## 👋 마치며\n깔끔하게 짜여진 소스는 아니지만 언젠가 필요할지도 모르겠다.\n\n"},{"excerpt":"️🧪 테스트 환경 Amazon Linux 2023 (EC2) PostgreSQL 17.2 ✋ 들어가며 PostgreSQL을 사용하면서 패스워드 복잡도와 같은 정책들을 적용하게 되었는데 다양한 정책을 쉽게 적용할 수 있는\n를 활용하기로 했다. 'pass123' 같은 쉬운 패스워드를 설정하지 못하게 하려면  패키지를 추가로 설치해야하는데 이 글에서는 다루지 …","fields":{"slug":"/postgresql-password-policy-credcheck/"},"frontmatter":{"date":"March 12, 2025","title":"PostgreSQL 패스워드 정책 설정 (CredCheck)","tags":["postgresql","ec2"],"emoji":"📃","series":null},"rawMarkdownBody":"\n## ️🧪 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - PostgreSQL 17.2\n\n## ✋ 들어가며\nPostgreSQL을 사용하면서 패스워드 복잡도와 같은 정책들을 적용하게 되었는데 다양한 정책을 쉽게 적용할 수 있는\n`CredCheck`를 활용하기로 했다. 'pass123' 같은 쉬운 패스워드를 설정하지 못하게 하려면 `cracklib` 패키지를 추가로 설치해야하는데 이 글에서는 다루지 않는다.\n\n## 🏗️ CredCheck 확장프로그램 설치하기\n\n#### ***다운로드***\n만약 Git이 설치되어있지 않다면 [CredCheck↗](https://github.com/HexaCluster/CredCheck)에서 다운받아 아래 경로에 올려둔다.\n\n```shell\ncd `PostgreSQL설치경로`/share/contrib\ngit clone https://github.com/MigOpsRepos/CredCheck\n```\n\n#### ***설치 전 설정***\nMakefile을 열어서 PG_CONFIG 경로를 지정한다. \n\n```shell\ncd `PostgreSQL설치경로`/share/contrib/credcheck\nvi Makefile\n```\n\n```shell\n...\n#PG_CONFIG = pg_config\nPG_CONFIG = `PostgreSQL설치경로`/bin/pg_config\n...\n```\n\n#### ***컴파일 및 설치***\n```shell\nmake\nmake install\n```\n\n#### ***설치 후 설정***\nPostgreSQL 데이터 경로에서 `postgresql.conf`를 아래와 같이 수정한다.\n\n```shell\nvi `PostgreSQL데이터경로`/postgresql.conf\n```\n```shell\n...\n#shared_preload_libraries = ''          # (change requires restart)\nshared_preload_libraries = '$libdir/credcheck'\n...\n```\n\n### ***DB 설정***\n데이터베이스에 접근 후 쿼리로 CredCheck 확장 프로그램을 활성화한다.\n\n```sql\ncreate extension credcheck;\nselect * from pg_extension;\n```\n\n아래와 같이 CredCheck 확장 프로그램이 활성화된걸 확인할 수 있다.\n```shell\n✔\n  oid  |  extname  | extowner | extnamespace | extrelocatable | extversion | extconfig | extcondition\n-------+-----------+----------+--------------+----------------+------------+-----------+--------------\n 22488 | credcheck |       10 |         2200 | f              | 3.0.0      |           |\n...\n```\n\n\n## 🔐️ PostgreSQL 패스워드 정책 설정\n설치가 완료되었으면 이제 아주 간단하게 패스워드 정책을 설정할 수 있다. 모든 작업은 데이터베이스에 접근해서 쿼리로 수행한다.\n\n#### ***사용가능한 정책 목록***\n\n| Check                       | Type     | Description                                         \t\t\t\t\t\t\t\t\t  |\n|-----------------------------|----------|------------------------------------------------------------------------------------------|\n| `username_min_length      ` | username | 사용자 이름의 최소 길이                            \t\t\t\t\t\t\t\t\t  |\n| `username_min_special     ` | username | 최소 특수 문자 수                                  \t\t\t\t\t\t\t\t\t  |\n| `username_min_digit       ` | username | 최소 숫자 수                                      \t\t\t\t\t\t\t\t\t  |\n| `username_min_upper       ` | username | 최소 대문자 수                                    \t\t\t\t\t\t\t\t\t  |\n| `username_min_lower       ` | username | 최소 소문자 수                                    \t\t\t\t\t\t\t\t\t  |\n| `username_min_repeat      ` | username | 문자가 반복될 수 있는 최대 횟수                    \t\t\t\t\t\t\t\t\t  |\n| `username_contain_password` | username | 사용자 이름에 비밀번호가 포함되어서는 안 됨         \t\t\t\t\t\t\t\t\t  |\n| `username_contain         ` | username | 사용자 이름에 다음 문자 중 하나가 포함되어야 함   \t\t\t\t\t\t\t\t\t  |\n| `username_not_contain     ` | username | 사용자 이름에 다음 문자가 포함되어서는 안 됨      \t\t\t\t\t\t\t\t\t  |\n| `username_ignore_case     ` | username | 위의 검사를 수행할 때 대소문자를 무시함           \t\t\t\t\t\t\t\t\t  |\n| `password_min_length      ` | password | 비밀번호의 최소 길이                                \t\t\t\t\t\t\t\t\t  |\n| `password_min_special     ` | password | 최소 특수 문자 수                                  \t\t\t\t\t\t\t\t\t  |\n| `password_min_digit       ` | password | 비밀번호의 최소 숫자 수                            \t\t\t\t\t\t\t\t\t  |\n| `password_min_upper       ` | password | 최소 대문자 수                                    \t\t\t\t\t\t\t\t\t  |\n| `password_min_lower       ` | password | 최소 소문자 수                                    \t\t\t\t\t\t\t\t\t  |\n| `password_min_repeat      ` | password | 문자가 반복될 수 있는 최대 횟수                    \t\t\t\t\t\t\t\t\t  |\n| `password_contain_username` | password | 비밀번호에 사용자 이름이 포함되어서는 안 됨        \t\t\t\t\t\t\t\t\t  |\n| `password_contain         ` | password | 비밀번호에 다음 문자가 포함되어야 함               \t\t\t\t\t\t\t\t\t  |\n| `password_not_contain     ` | password | 비밀번호에 다음 문자가 포함되어서는 안 됨         \t\t\t\t\t\t\t\t\t  |\n| `password_ignore_case     ` | password | 위의 검사를 수행할 때 대소문자를 무시함           \t\t\t\t\t\t\t\t\t  |\n| `password_valid_until     ` | password | 최소 일수와 함께 CREATE ROLE 문에서 VALID UNTIL 절 사용 강제화                       |\n| `password_valid_max       ` | password | 최대 일수와 함께 CREATE ROLE 문에서 VALID UNTIL 절 사용 강제화                       |\n\n#### ***정책 적용 방법***\n`ALTER SYSTEM SET` 구문을 이용해서 위 정책들을 하나씩 설정할 수 있다.\n\n```sql\nALTER SYSTEM SET credcheck.password_min_length = 8; -- 비밀번호의 최소 길이\nALTER SYSTEM SET credcheck.password_min_special = 1; -- 특수문자 포함\nALTER SYSTEM SET credcheck.password_min_digit = 1; -- 숫자 포함\nALTER SYSTEM SET credcheck.password_min_upper = 1; -- 대문자 포함\nALTER SYSTEM SET credcheck.password_min_lower = 1; -- 소문자 포함\nALTER SYSTEM SET credcheck.password_contain_username  = on; -- 사용자명 포함 불가\n\nSELECT pg_reload_conf();\n```\n\n설정된 정책을 확인하기 위해서는 `SHOW` 구문을 사용해서 출력한다.\n```sql\nSHOW credcheck.password_min_length;\n```\n```shell\n✔\n credcheck.password_min_length\n-------------------------------\n 8\n```\n\n#### ***테스트***\n위 설정이 모두 끝났다면 실제로 User를 생성해보면 정상적으로 설정되었는지 확인할 수 있다.\n\n```sql\nCREATE USER aa WITH PASSWORD 'aaa';\n```\n\n설정하려고하는 패스워드의 길이가 8자리가 안되기 떄문에 어림없다는 메시지와 함께 정상 설정 되었음을 알 수 있다.\n```shell\n```sql\n✔\nERROR:  password length should match the configured credcheck.password_min_length (8)\n```\n\n## 👋 마치며\nPostgreSQL에서 안전한 비밀번호 관리 절차와 작성 규칙을 수립하기 위해서 `CredCheck`를 사용해봤는데 간단하고 유용한 것 같다.\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) ✋ 들어가며 SSH 프로토콜의 포트는 일반적으로 기본 포트인 22번 포트를 사용하는데\n자동화된 스크립트를 통한 공격이나 불필요한 접근을 차단하는 등 보안을 강화하기 위해서 포트를 변경하는 시스템들이 많이 있다. RHEL(Red Hat Enterprise Linux) 환경에서 어떻게 포트를 변경하는…","fields":{"slug":"/amazon-linux-rhel-ssh-port/"},"frontmatter":{"date":"March 10, 2025","title":"리눅스 SSH 포트 변경 (Amazon Linux, RHEL)","tags":["aws","ec2","amazon-linux","linux"],"emoji":"🔐","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n\n## ✋ 들어가며\nSSH 프로토콜의 포트는 일반적으로 기본 포트인 22번 포트를 사용하는데\n자동화된 스크립트를 통한 공격이나 불필요한 접근을 차단하는 등 보안을 강화하기 위해서 포트를 변경하는 시스템들이 많이 있다.\n\nRHEL(Red Hat Enterprise Linux) 환경에서 어떻게 포트를 변경하는지 알아보겠다. \n\n## 🔄️ SSH 포트 변경하기\nRHEL 환경에서 SSH 포트를 변경하는 방법은 아주 간단하다. 설정 파일을 열어서 포트를 변경한 후 SSH 서비스를 재시작하면 끝\n\n#### ***설정 파일 수정***\n```shell\nvi /etc/ssh/sshd_config\n```\n```shell\n# semanage port -a -t ssh_port_t -p tcp #PORTNUMBER\n#\n# Port 22\nPort 2222\n...\n```\n#### ***sshd 재시작***\n```shell\nsystemctl restart sshd\n```\n\n#### ***변경된 포트 확인***\n```shell\nnetstat -nlp | grep sshd\n```\n```shell\n✔\ntcp        0      0 0.0.0.0:2222            0.0.0.0:*               LISTEN      2313825/sshd: /usr/\ntcp6       0      0 :::2222                 :::*                    LISTEN      2313825/sshd: /usr/\n```\n\n\n## 👋 마치며\n아주 간단한 방법으로 SSH 포트 변경이 가능한데도 매번 변경을 진행할 때마다 잘 생각이 안나는데 이참에 기록해뒀으니 다른 블로그는 안찾아봐도 될 것 같다.\n\n"},{"excerpt":"✋ 들어가며 프리랜서 아키텍처 혹은 개발자로 대부분의 시간을 살아오면서 GitOps에 대한 경험을 할 기회가 많지 않았는데 최근 프로젝트에서 클라우드 인프라를 관리하기 위한 워크플로우를 경험하게 되었다. 🔎 GitOps가 뭐야? GitOps는 Git 리포지토리를 단일 정보 소스로 사용하여 인프라를 코드로 제공하며, 제출된 코드에서는 CI 프로세스를 확인하…","fields":{"slug":"/gitops-workflow/"},"frontmatter":{"date":"March 05, 2025","title":"GitOps Workflow에 대한 나의 경험","tags":["gitops","aws","kubernetes"],"emoji":"🏢","series":null},"rawMarkdownBody":"\n## ✋ 들어가며\n프리랜서 아키텍처 혹은 개발자로 대부분의 시간을 살아오면서 GitOps에 대한 경험을 할 기회가 많지 않았는데 최근 프로젝트에서 클라우드 인프라를 관리하기 위한 워크플로우를 경험하게 되었다.\n\n\n## 🔎 GitOps가 뭐야?\n\nGitOps는 Git 리포지토리를 단일 정보 소스로 사용하여 인프라를 코드로 제공하며, 제출된 코드에서는 CI 프로세스를 확인하고,\nCD 프로세스에서는 보안, 코드형 인프라(IaC) 또는 애플리케이션 프레임워크에 설정된 기타 경계와 같은 요구 사항을 확인하고 적용한다.\n코드에 대한 모든 변경 사항이 추적되므로 업데이트를 손쉽게 수행할 수 있으며 롤백이 필요한 경우 버전 제어 기능도 제공된다.\n\n## 💡 GitOps의 핵심 아이디어\n\n- 배포에 관련된 모든 것을 선언형 기술서(Declarative Descriptions) 형태로 작성하여 Config Repository(혹은 Environment Repository)에서 관리한다. \n- Config Repository의 선언형 기술서와 운영 환경 간 상태 차이가 없도록 유지시켜주는 자동화 시스템을 구성한다.\n\n## 🎡 내가 경험해본 GitOps Workflow\n\n최근 프로젝트에서 경험했던 GitOps의 Workflow는 아래 작성한 이미지로 요약할 수 있다.\n\n![](images/20250304_125653.png)\n\n#### ***흐름을 살쳐보면..***\n\n1) 애플리케이션 소스를 Source Repository에 Push한다.\n2) 이전 단계에서 Webhook이 발생하거나 수동으로 처리하는 빌드 등의 Trigger가 발생하면 Jenkins에서 최신 소스를 내려받아서 이후 파이프라인에 작성된 절차가 수행된다.\n3) 내려받은 최신소스의 빌드를 진행하고 생성된 Container Image를 Amazon ECR(Elastic Container Registry)에 Push한다.\n4) Helm Chart를 사용해서 매니페스트 템플릿에 Container Image ID를 포함한 설정 정보를 변경하고 Config Repository에 Push한다.\n   <br/><br/>_그림에는 표현되어있지 않지만 IaC(Infrastructure as Code)를 활용해서 Amazon EKS(Elastic Kubernetes Service) 클러스터가 생성되어있는데 이때는 Terraform이 사용되었다._\n5) ArgoCD에서 Config Repository에 의도된 상태와 현재 상태의 차이를 감지한다. \n6) Config Repository를 기반으로 EKS 클러스터에 동기화를 수행한다.\n\n## 📖 참고자료\n\n> [GitOps란: Git 기반의 지속적인 운영 및 배포 방법론 적용](https://www.redhat.com/ko/topics/devops/what-is-gitops)\n> <br/>\n> [데브옵스의 확장 모델 – 깃옵스(GitOps) 이해하기 | 인사이트리포트 | 삼성SDS](https://www.samsungsds.com/kr/insights/gitops.html)\n\n## 👋 마치며\n\nAWS에서 이러한 환경을 경험해봤는데 더 깊이있는 이해를 위해서 다시 한번 실습해보는 시간을 가져봐야겠다."},{"excerpt":"✋ 들어가며 필자가 계속 업데이트 사용하고 있는 Gatsby Blog 테마↗에도 Mermaid 문법을 지원하도록 업데이트 되었다.\n기술 블로그를 운영하다보면 다이어그램이나 플로우차트를 포함한 다양한 차트를 그려서 설명해야하는 경우가 생긴다. 이미지를 제작 후 삽입하는 형태보다 Mermaid 문법을 사용하면 좋을 것 같아서 소개해보려고 한다. ☀️ 테스트 환…","fields":{"slug":"/gatsby-mermaid-syntax-flowchart/"},"frontmatter":{"date":"February 27, 2025","title":"Gatsby 마크다운에 Flowchart 그리기 (Mermaid 문법)","tags":["github-pages","blog","gatsby","markdown","mermaid"],"emoji":"🧜","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n## ✋ 들어가며\n필자가 계속 업데이트 사용하고 있는 [Gatsby Blog 테마↗](https://github.com/rundevelrun/gatsby-starter-rundevelrun)에도 Mermaid 문법을 지원하도록 업데이트 되었다.\n기술 블로그를 운영하다보면 다이어그램이나 플로우차트를 포함한 다양한 차트를 그려서 설명해야하는 경우가 생긴다. 이미지를 제작 후 삽입하는 형태보다 Mermaid 문법을 사용하면 좋을 것 같아서 소개해보려고 한다.\n\n\n## ☀️ 테스트 환경\n> - NodeJS v22.13.0\n> - yarn 1.22.22\n\n## 🔎 Mermaid란 무엇인가\nMermaid는 JavaScript 기반의 다이어그램 및 차트 도구로,\n마크다운에 작성된 텍스트를 렌더링하여 다이어그램을 동적으로 생성할 수 있는 도구라고 [공식문서↗](https://mermaid.js.org/intro/)에 소개되어있고 AI 친구에게 번역을 부탁한 후 그대로 가져왔다.\n\n## 🧜 Gatsby에 Mermaid 플러그인 설치하기\n[Gatsby Blog 테마↗](https://github.com/rundevelrun/gatsby-starter-rundevelrun)를 사용하고 있다면 Mermaid 플러그인이 설치되어있지만 그렇지 않은 방문자를 위해 아주 간단한 설치방법을 소개해보겠다.\n\n\n#### ***의존성 패키지 설치***\n\n`package.json`에 의존성 패키지를 추가하고 설치를 진행한다. \n\n```json\n...\n  \"dependencies\": {\n    \"gatsby-remark-mermaid\": \"^5.0.0\",\n    \"playwright\": \"^1.50.1\",\n...\n```\n\n#### ***gatsby 설정 수정***\n\n`gatsby-config.js`의 gatsby-transfomer-remark 하위에 gatsby-remark-mermaid를 추가하면 끝.\n```js\nmodule.exports = {\n  plugins: [\n  {\n    resolve: `gatsby-transformer-remark`,\n    options: {\n      plugins: [\n        `gatsby-remark-mermaid`,\n...\n```\n\n## 📝 Mermaid 문법 사용하기\nFlowchart, Gantt, Kanban, Mindmaps, Git 등 다양한 다이어그램 문법을 지원하는데 몇개만 살펴보도록 하겠다.\n\n#### ***Flowchart 예제***\n\n````\n--- \ntitle: Example\n---\nflowchart LR\n    A[Start] --> B{isYN}\n    B -- Y --> C[Success]\n    B -- N --> D[Fail]\n````\n\n```mermaid\n--- \ntitle: Example\n---\nflowchart LR\n    A[Start] --> B{isYN}\n    B -- Y --> C[Success]\n    B -- N --> D[Fail]\n```\n\n#### ***Pie Chart 예제***\n````\n```\npie title Example\n    \"Python\": 20.17\n    \"C++\": 10.75\n    \"Java\": 6.45\n    \"C\":8.89\n    \"C#\":6.08\n```\n````\n\n```mermaid\npie title Example\n    \"Python\": 20.17\n    \"C++\": 10.75\n    \"Java\": 6.45\n    \"C\":8.89\n    \"C#\":6.08\n```\n\n### ***Architecture 예제***\n\n````\n```mermaid\narchitecture-beta\n    group api(cloud)[Example]\n    \n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n    \n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db\n```\n````\n\n```mermaid\narchitecture-beta\n    group api(cloud)[Example]\n    \n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n    \n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db\n```\n\n#### ***Git Diagram 예제***\n\n````\n\n```mermaid\n---\ntitle: Example\n---\ngitGraph\n    commit\n    branch develop\n    commit\n    branch bugfix\n    commit\n    commit\n    checkout develop\n    merge bugfix\n    branch feature\n    checkout feature\n    commit\n    commit\n    checkout develop\n    merge feature\n    checkout main\n    merge develop\n    \n\n```\n````\n\n\n```mermaid\n---\ntitle: Example\n---\ngitGraph\n    commit\n    branch develop\n    commit\n    branch bugfix\n    commit\n    commit\n    checkout develop\n    merge bugfix\n    branch feature\n    checkout feature\n    commit\n    commit\n    checkout develop\n    merge feature\n    checkout main\n    merge develop\n```\n\n## 👋 마치며\n소개한 다이어그램과 차트 외에도 아주 다양한 문법을 지원하고 있는데 어디에 써먹으면 좋을지는 모르겠지만 Git Diagram이 뭔가 마음에 든다."},{"excerpt":"☀️ 테스트 환경 Windows 11 Pro IntelliJ IDEA 2024.3 (Ultimate Edition) ✋ 들어가며  시리즈를 진행하면서 팔자에도 없던 Flutter 환경 설정의 맛을 조금 봤다.\n글을 작성하는 환경은 Windows지만 MacOS에서도 거의 동일하게 세팅이 가능해서 내용을 공유해보려고 한다. ❓ IntelliJ를 왜 선택했나 F…","fields":{"slug":"/flutter-sdk-install-intellij/"},"frontmatter":{"date":"February 25, 2025","title":"Flutter 개발환경 설정하기 (with. IntelliJ)","tags":["intellij","flutter"],"emoji":"🎯","series":"💰 무작정 모바일 앱 출시하기"},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Windows 11 Pro\n> - IntelliJ IDEA 2024.3 (Ultimate Edition)\n\n## ✋ 들어가며\n`무작정 모바일 앱 출시하기` 시리즈를 진행하면서 팔자에도 없던 Flutter 환경 설정의 맛을 조금 봤다.\n글을 작성하는 환경은 Windows지만 MacOS에서도 거의 동일하게 세팅이 가능해서 내용을 공유해보려고 한다.\n\n\n## ❓ IntelliJ를 왜 선택했나\nFlutter 공식 문서에는 `Visual Studio Code`를 사용하는 방법과 `Android Studio`, `IndelliJ IDEA`를 사용한 개발환경 구성 방식이 인기있는 옵션이라고 소개하고 있다.\n\n필자는 VSCode는 별로 선호하지 않고 익숙하지 않은데다가 무려 JetBrains를 신봉하는 사람이다.\n그럼 선택지가 Android Studio와 IntelliJ가 남아있는데 어차피 IntelliJ로 만들어져있는 Android Studio는 사용하지 않기로 했다.\n\n\n## 🎯 Flutter 개발환경을 설정해보자\nFlutter 개발환경을 가볍게 구성해보고 `Hello World!`와 같은 첫 페이지를 띄워보는게 이번 게시글의 핵심이 되겠다.\n\n#### ***1. Flutter SDK 다운로드***\n- [공식 설치 가이드↗](https://docs.flutter.dev/get-started/install)에 접속 후 아래 과정을 따라가보자.\n\n- 현재 설치하고자 하는 플랫폼을 선택한다.\n\n  ![](images/20250225_133646.png)\n\n- 지금 단계에서는 Flutter SDK를 다운받는게 목표이기 때문에 앱 유형은 크게 상관없다.\n\n  ![](images/20250225_133730.png)\n\n\n- 아래와 같이 최신버전의 Flutter SDK를 다운받을 수 있다.\n\n  ![](images/20250225_133822.png)\n\n- 다운받은 압축파일을 적당한 위치에 압축을 풀어놓으면 끝 (e.g. `C:\\flutter`)\n\n\n#### ***2. IntelliJ Plugins 설치***\n- `Settings ➡ Plugins`에서 flutter를 검색 후 설치한다.\n\n  ![](images/20250225_135009.png)\n\n- 아래와 같이 `Android`, `Dart`, `Flutter`가 한번에 설치되었음을 알 수 있다. \n\n  ![](images/20250225_140419.png)\n\n\n#### ***3. 신규 프로젝트 생성***\n- 새프로젝트를 생성하고 위에서 압축을 풀었던 Flutter SDK 경로를 넣어준다.\n\n  ![](images/20250225_140600.png)\n\n- 지원할 플랫폼 등의 필수 요소들을 입력하면 끝이다.\n\n  ![](images/20250225_140653.png)\n\n#### ***4. Hello World!***\n- 환경설정이 정상이라면 아래와 같은 화면이 나오는데 실행할 Device를 선택 후 실행 버튼을 눌러준다. (Web Browser, Android Emulator, iOS Simulator, Physical device 등을 지원)\n\n  ![](images/20250225_141011.png)\n\n- 잠시 기다리면 `Hello World!`라고 부르기에는 너무 거창한 초기 화면이 보여진다. 심지어 `+` 버튼을 누르면 숫자가 올라간다.\n\n  ![](images/20250225_141322.png)\n\n\n## 👋 마치며\n이렇게 팔자에도 없던 Flutter의 개발환경을 구성해봤는데, 한가지 소스로 멀티 플랫폼을 지원한다는게 너무 만족스럽다.\n하지만 아무리 멀티 플랫폼을 지원하더라도 디자인에 센스가 제로에 가까워서 예쁜 앱을 만들어내기에는 힘들 것 같다. (~~그래서 대충 만들기로 나 자신과 협의했다~~)"},{"excerpt":"☀️ 테스트 환경 AWS Console ✋ 들어가며 개인정보보호법과 정보통신망법 기준을 충족하기 위해서 이미 생성 후 사용중인 Amazon EBS 볼륨의 암호화가 필요했다.\n글을 쓰고 있는 지금(2025-02-24)를 기준으로 이미 생성된 EBS 볼륨의 암호화 설정을 변경하는 것은 불가능하기 때문에 다른 방법이 필요했다. 🏫 EBS란? 우리가 아는 그 교육…","fields":{"slug":"/amazon-ec2-ebs-encrypt/"},"frontmatter":{"date":"February 24, 2025","title":"사용중인 Amazon EBS 암호화하기 (EC2에 연결된 상태)","tags":["aws","ec2","ebs"],"emoji":"🔒","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - AWS Console\n\n## ✋ 들어가며\n개인정보보호법과 정보통신망법 기준을 충족하기 위해서 이미 생성 후 사용중인 Amazon EBS 볼륨의 암호화가 필요했다.\n글을 쓰고 있는 지금(2025-02-24)를 기준으로 이미 생성된 EBS 볼륨의 암호화 설정을 변경하는 것은 불가능하기 때문에 다른 방법이 필요했다.\n\n## 🏫 EBS란?\n우리가 아는 그 교육 방송 말고 EBS(Elastic Block Store)는 AWS에서 제공하는 블록 스토리지 서비스로 EC2에 연결해서 사용할 수 있는 스토리지 볼륨을 제공한다.\n블록 단위로 데이터를 저장하며 EC2 인스턴스가 종료되더라도 데이터가 유지된다는 특징이 있다.\n\n더 자세한 내용이 궁금하다면 [여기↗](https://aws.amazon.com/ko/ebs/) 공식 홈페이지를 살펴보자.\n\n## 🔒 EBS 암호화하기\nAWS EBS를 암호화하기 위해서는 크게 6단계의 과정이 필요한데 모두 AWS Console에서 이루어지며 EC2 중지와 시작과 같은 간단한 절차로 구성되어있어서 큰 어려움은 없을 것으로 예상이 된다.\n\n가장 먼저 암호화되지 않은 볼륨을 확인하고 천천히 한걸음씩 따라가보자.\n\n![](images/20250221_111956.png)\n\n#### ***1. EC2 중지***\n`EC2 ➡ 인스턴스`\n\n암호화가 필요한 EBS 볼륨이 연결된 EC2를 중지한다. 현재를 기준으로 스냅샷을 생성할 예정이기 때문에 더이상의 업데이트가 이루어지지 않도록 한다.\n\n![](images/20250221_112256.png)\n\n#### ***2. EBS 볼륨 분리***\n`EC2 ➡ Elastic Block Store ➡ 볼륨`\n\n암호화되지 않은 EBS 볼륨을 EC2에서 분리해준다.\n\n![](images/20250221_131037.png)\n\n#### ***3. 스냅샷 생성***\n`EC2 ➡ Elastic Block Store ➡ 볼륨`\n\n분리된 EBS 볼륨의 스냅샷을 생성한다.\n\n![](images/20250221_131207.png)\n\n![](images/20250221_131350.png)\n\n`EC2 ➡ Elastic Block Store ➡ 스냅샷`\n\n스냅샷 화면에서 생성된 스냅샷을 확인 할 수 있고 스냅샷의 상태가 '완료됨'으로 표시되어야 다음 단계로 넘어갈 수 있다.\n필자는 512GB의 볼륨의 스냅샷을 생성하는데 거의 2시간이 소요된 것 같다.\n\n![](images/20250221_133726.png)\n\n#### ***4. 암호화 EBS 볼륨 생성***\n`EC2 ➡ Elastic Block Store ➡ 볼륨`\n\n스냅샷의 생성이 완료되었다면 해당 스냅샷을 이용해서 암호화된 볼륨을 생성할 차례이다.\n\n![](images/20250221_131533.png)\n\n데이터 복원을 위해서 생성된 스냅샷 ID를 선택해주고 우리의 목표인 볼륨 암호화를 꼭 체크해준다. \n\n![](images/20250221_131929.png)\n\n아래와 같이 암호화된 볼륨이 생성되면 정상이고 암호화되지 않은 기존 볼륨은 삭제해도 좋다.\n\n![](images/20250221_151536.png)\n\n#### ***5. EBS 볼륨 연결***\n\n거의 마지막까지 왔는데 이 단계에서는 지금까지 생성한 암호화된 EBS 볼륨을 기존 EC2에 연결해준다.\n(필자는 연결 후에 화면을 캡쳐해서 '볼륨 연결'이 비활성화 되어있다.)\n\n![](images/20250221_151730.png)\n\n연결할 EC2 인스턴스를 선택하고 기존에 연결되어있던 디바이스 이름을 선택한다.\n별도의 설정이 없었다면 대부분 `/dev/xvda`으로 되어있다.\n\n![](images/20250221_151921.png)\n\n#### ***6. EC2 시작***\n마지막으로 1번 단계에서 중지했던 EC2를 시작하면 끝.\n이 과정도 평소의 시간보다는 조금 더 오래걸리고 퍼블릭 IP와 DNS가 변경되니 놀라지말자.\n\n\n## 👋 마치며\n어느새 벌써 24번째 게시글인데 여전히 방문자는 없다."},{"excerpt":"🏗️ 데이터를 만들어볼까? 본격적으로 운전면허 학과시험 문제은행 DB를 만들었던 과정을 작성하려고 한다.\n이 과정이 완전한 자동이었으면 좋겠지만 수작업이 다수 포함되어있어서 소스코드의 언급은 최소화하려고 한다. 👨‍🍳 자동인데.. 그 약간 수동을 곁들인.. 🔤 일단 PDF에서 텍스트만 뽑아내자  한국도로교통공단에서 제공하는 PDF는 위와 같은 형태로 구성이 되…","fields":{"slug":"/create-app-question-answer-database-2/"},"frontmatter":{"date":"February 05, 2025","title":"운전면허 학과시험 문제은행 DB 만들기 2","tags":["에세이","앱만들기"],"emoji":"💾","series":"💰 무작정 모바일 앱 출시하기"},"rawMarkdownBody":"\n## 🏗️ 데이터를 만들어볼까?\n\n본격적으로 운전면허 학과시험 문제은행 DB를 만들었던 과정을 작성하려고 한다.\n이 과정이 완전한 자동이었으면 좋겠지만 수작업이 다수 포함되어있어서 소스코드의 언급은 최소화하려고 한다.\n\n> 👨‍🍳 *자동인데.. 그 약간 수동을 곁들인..*\n\n## 🔤 일단 PDF에서 텍스트만 뽑아내자\n\n![](images/20250205_160753.png)\n\n한국도로교통공단에서 제공하는 PDF는 위와 같은 형태로 구성이 되어있고\n문항의 수, 정답의 수, 이미지 포함 여부, 이미지 설명 포함 여부 등이 문제마다 조금씩 다르다.\n\n#### ***모르겠고..***\n\n이미지나 동영상은 일단 지금 모르겠고 아무 생각도 안나니까 나중에 생각할거고 비교적 간단해보이는(?) 텍스트라도 먼저 뽑아보자는게 내 생각이었다.\n\n#### ***PDF에서 텍스트 출력하기***\n\n아래와 같은 간단하게 만든 자바 소스로 PDF에 포함된 모든 텍스트를 출력할 수 있었다.\n\n```JAVA\n// org.apache.pdfbox:podfbox:2.0.29\nPDDocument doc = PDDocument.load(new File(\"../question_bank.pdf\"));\nString text = new PDFTextStripper().getText(doc);\n...\n```\n\n아래와 같이 텍스트를 출력했더니 앞에 3문제만 뽑아왔는데도 문제에 줄바꿈이 있는 경우, 한줄에 문항이 여러개인 경우 등 정형화되지 않은 패턴들이 보이기 시작했다.\n게다가 패턴과 다르게 띄어쓰기가 표함된 경우, 문항 번호가 로마 숫자로 표기된 경우, 심지어는 문항 번호가 없는 경우 등의 패턴을 알 수 없는 단순 오타들도 많이 포함되어 있었다.  \n\n```text\n[예시]\n\n1. 다음 중 총중량 1.5톤 피견인 승용자동차를 4.5톤 화물자동차로 견인하는 경우 필요한 운전면허에 해당하지 않은 \n것은?\n ① 제1종 대형면허 및 소형견인차면허  ② 제1종 보통면허 및 대형견인차면허\n ③ 제1종 보통면허 및 소형견인차면허  ④ 제2종 보통면허 및 대형견인차면허\n■ 정답：4\n■ 해설：도로교통법 시행규칙 별표18 총중량 750킬로그램을 초과하는 3톤 이하의 피견인 자동차를 견인하기 위해서는 견인\n하는 자동차를 운전할 수 있는 면허와 소형견인차면허 또는 대형견인차면허를 가지고 있어야 한다.\n\n2. 도로교통법령상 운전면허증 발급에 대한 설명으로 옳지 않은 것은? \n ① 운전면허시험 합격일로부터 30일 이내에 운전면허증을 발급받아야 한다.\n ② 영문운전면허증을 발급받을 수 없다. \n ③ 모바일운전면허증을 발급받을 수 있다.\n④ 운전면허증을 잃어버린 경우에는 재발급 받을 수 있다.\n■ 정답：2\n■ 해설：도로교통법시행규칙 제77조∼제81조\n\n3. 시·도경찰청장이 발급한 국제운전면허증의 유효기간은 발급받은 날부터 몇 년인가?\n ① 1년    ② 2년  ③ 3년  ④ 4년\n■ 정답：1\n■ 해설：도로교통법 제98조에 따라 국제운전면허증의 유효기간은 발급받은 날부터 1년이다.\n...\n```\n\n그래서 원하는 패턴이 아닌 경우를 찾아내는 검증 로직이 필요해졌다. (~~아 귀찮아~~)\n\n## 🔎 정형화되지 않은 패턴 찾기\n\n#### ***원하는 패턴***\n\n내가 원하는 정형화된 패턴의 최종 모습은 아래와 같은 모습이었다.\n\n```text\n[예시]\n\n724. 다음 상황에서 가장 안전한 운전방법 2가지는?\n ① 도로 공사 중이므로 전방 상황을 잘 주시하며 운전한다.\n ② 노면이 고르지 않으므로 속도를 줄이지 않고 빠르게 진행하는 것이 안전하다.\n ③ 맞은편에서 진행하는 차량에 주의하며 서행한다.\n ④ 경음기를 계속 사용하며 우측의 주차되어 있는 공사 차량에 경고하고 속도를 높여 신속하게 진행한다.\n ⑤ 맞은편에서 진행하는 차량이 가까워질 때까지 속도를 유지하다가 급정지한다. \n■ 공사 중인 도로\n■ 맞은편에서 진행해오는 차량\n■ 길 우측에 주차시켜 놓은 공사 차량\n■ 정답 : 1, 3\n■ 해설 : 공사 중인 이면도로에서는 돌발 상황에 대비하여 속도를 줄이고 예측·방어·양보 운전한다.\n```\n\n순서대로 살펴보면 아래와 같다.\n\n1. 첫줄에는 문항 번호가 포함된 문제\n2. 이후 4~5줄에는 문항\n3. 이후 정답 라인이 나오기 전 이미지의 설명이 있다면 표시\n4. 정답 표시\n5. 해설이 여러줄 표시\n\n#### ***패턴 검증 로직 작성***\n\nPDF에서 뽑아낸 텍스트를 한줄씩 읽으면서 패턴에 맞지 않는 라인을 로그에 남기고\n혹시모르는 상황에 대비해서 최대한 눈으로 확인하는 과정을 거치고 수정 로직을 만들어서 변경하거나 경우에 따라서는 수작업으로 텍스트를 변경했다.\n너무 많은 패턴이 존재했기 때문에 이 과정이 가장 오래 걸리는 작업이었다.\n\n```JAVA\n// 한줄에 ①, ②가 같이 있는 경우\nif (line.contains(\"①\") && line.contains(\"②\")) {\n    System.out.println(nowQuestionNumber - 1 + \" \" + line);\n}\n\n...\n```\n\n#### ***그래서 결과는?***\n\n위에서 가공한 텍스트에 문제 유형과 점수를 포함해서 아래와 같은 JSON 구조로 변환했다.\n이미지와 동영상은 어떤식으로 관리할지 아직 고민중에 있고 화면을 만들어나가는 단계에서 구체화할 예정이다.\n\n```json\n[가공된 데이터]\n\n...\n{\n  \"type\": 3,\n  \"score\": 3,\n  \"num\": 800,\n  \"question\": \"왼쪽차로(1차로)에서 직진하며 교차로에 접근하고 있는 상황이다. 안전한 운전방법 2가지는?\",\n  \"choice1\": \"반대쪽 방향에 차가 없으므로 왼쪽으로 앞지르기하여 통과한다.\",\n  \"choice2\": \"감속하며 1차로 택시와 안전한 거리를 두고 접근한다.\",\n  \"choice3\": \"경음기을 사용하여 택시를 멈추게 하고 택시의 오른쪽으로 빠르게 통행한다.\",\n  \"choice4\": \"3차로로 연속 진로변경하여 정차한다.\",\n  \"choice5\": \"2차로로 진로변경하는 경우 택시와 보행자에 접근 시 감속한다. \",\n  \"description1\": \"교통정리가 없는 교차로\",\n  \"description2\": \"양방향 주차된 차들\",\n  \"description3\": \"오른쪽 후사경에 접근 중인 승용차\",\n  \"answer\": \"2,5\",\n  \"explanation\": \"1차로에 통행중인 택시가 오른쪽 보행자를 확인하고 제동하며... \\n...\"\n},\n...\n```\n\n위 JSON 데이터는 사실 최종 모습이 아니다.\n필자는 데이터를 최대한 사용하지 않는 앱을 원하기 때문에 JSON 데이터를 에셋에 포함시켜야하는데\n이전 글에서 내가 했던 것 처럼 내 앱의 압축을 풀었을때 데이터들을 알아보기 어렵게 하기 위해서 암호화를 진행했다. \n\n드디어 PDF에 포함된 텍스트들이 내가 원하는 모습으로 변했다.\n\n```text\n[암호화된 데이터]\n\n6LsRfvEAyS8BWCQ+8+kKDe8GQot9EJsMyQf3rpPqAXDC55z2+pIVsf0pKAM6cUbwS+8+kKDe8GQot9EJsMyQ...\n```\n\n<adsense></adsense>\n\n## 🖼️ 이미지와 동영상은 어떻게?\n\n#### ***PDF에 포함된 이미지 저장하기***\n\n![](images/20250206_091855.png)\n\n먼저 텍스트를 뽑아낼떄와 똑같은 라이브러리를 활용해서 PDF에 포함된 모든 이미지를 저장하는 로직을 작성했다.\n아래 소스를 이용하면 페이지 번호화 페이지의 이미지 순번을 포함한 이미지를 저장할 수 있다.\n하지만 문제의 번호에 맞게 이미지명을 변환해야하고 예상치 못한 깨진 이미지들이 포함되어서 또 수작업으로 정리가 필요했다.\n\n```JAVA\n// org.apache.pdfbox:podfbox:2.0.29\nPDDocument doc = PDDocument.load(new File(\"../question_bank.pdf\"));\nString text = new PDFTextStripper().getText(doc);\n\nint pageCount = 1; // 페이지 번호\n\n// 페이지 순환\nfor (PDPage page : document.getPages()) {\n    PDResources resources = page.getResources();\n    \n    int imageCount = 0; // 이미지 번호\n    \n    // 이미지 순환\n    for (COSName xObjectName : resources.getXObjectNames()) {\n        if (resources.isImageXObject(xObjectName)) {\n            PDImageXObject image = (PDImageXObject) resources.getXObject(xObjectName);\n            BufferedImage bufferedImage = image.getImage();\n            \n            // 이미지 파일명 생성 (페이지 번호 및 이미지 순서 포함)\n            String imageName = \"image_\" + pageCount + \"_\" + imageCount + \".png\";\n            File outputFile = new File(\"../images\", imageName);\n            \n            // 이미지 파일로 저장\n            ImageIO.write(bufferedImage, \"PNG\", outputFile);\n            \n            imageCount++;\n        }\n    }\n    pageCount++;\n}\ndocument.close();\n...\n```\n\n#### ***동영상 저장하기***\n\n데이터화에 마지막 단계는 동영상 문제에 필요한 동영상을 저장하는 것이다.\n뭔가 한번에 내려받을 수 있으면 좋겠지만 그런거 없다.\n그저 [한국도로교통공단↗](https://www.safedriving.or.kr/notice/rerBankMovieList.do?menuCode=MN-PO-1153)에서 한땀 한땀 내려받았다.\n\n![](images/20250206_092235.png)\n\n35개 밖에 안되는데 뭐..\n한땀.. 한땀..\n\n## 👋 마치며\n이렇게 운전면허 학과시험 모의고사 어플을 만들기 위한 데이터 작업이 어느정도 정리됐다.\n다음은 어떤 모습의 앱을 만들어낼지 사용자에게 직접적으로 보여지는 UI/UX를 구성해보도록 하겠다.\n"},{"excerpt":"✋ 들어가며 한국도로교통공단에서는 운전면허 학과시험의 문제은행을 제공하며 문장형, 일러스트형, 사진형, 안전표지형, 동영상형 문제가 총 1,000문제로 구성되어있다.\n이 중에서 유형별로 정해진 수를 랜덤으로 뽑아서 출제되는데 1종과 2종의 문제는 같고 합격 점수가 1종은 70점, 2종은 60점으로 되어있다.  🤬 나한테 왜 그랬어.. PDF로 제공되는 문…","fields":{"slug":"/create-app-question-answer-database/"},"frontmatter":{"date":"February 04, 2025","title":"운전면허 학과시험 문제은행 DB 만들기 1","tags":["에세이","앱만들기"],"emoji":"💾","series":"💰 무작정 모바일 앱 출시하기"},"rawMarkdownBody":"\n## ✋ 들어가며\n한국도로교통공단에서는 운전면허 학과시험의 문제은행을 제공하며 문장형, 일러스트형, 사진형, 안전표지형, 동영상형 문제가 총 1,000문제로 구성되어있다.\n이 중에서 유형별로 정해진 수를 랜덤으로 뽑아서 출제되는데 1종과 2종의 문제는 같고 합격 점수가 1종은 70점, 2종은 60점으로 되어있다. \n\n## 🤬 나한테 왜 그랬어..\nPDF로 제공되는 문제 은행을 한땀 한땀 데이터화하고 기분좋게 위 '들어가며'를 작성하고 긴 명절 휴가를 다녀왔다.\n\n> 💣 ***청천벽력***\n> <br/><br/>\n> 그 사이에 문제은행이 변경됐다..\n\n과거의 데이터로 서비스를 제공할 수 없으니 PDF 파일에서 텍스트 따로 이미지를 따로 뽑아내고 동영상은 또 홈페이지에서 하나 하나 내려받았던 이 귀찮은 작업을 다시해야했다. <br/>\n어디가 어떻게 변경되었는지 상세하게 알려주기라도하면 좋을텐데.. ~~너무하네 진짜로~~\n\n## 📂 데이터를 어떻게 만들어낼까?\n\n#### ***문제은행 PDF 분석***\n<br/>파일을 열면 어떤식으로 데이터화를 해야할지 정말 막막하다. 사실 여러번 열어도 막막한데 그 이유를 살펴보자.\n\n- 생각보다 PDF 문서의 스크롤 압박이 심하다. (양이 많다.)\n- Excel 처럼 문서가 정형화되어있지 않아서 패턴을 찾기 어렵다.\n- 문제 번호가 없는 등 오타가 꽤 많이 숨어있다.\n- 문제의 유형이 다양하다. (이미지가 해설에 포함된 경우, 문제에 포함된 경우, 1개인 경우 2개인 경우, 이미지 설명이 N개 있는 유형 등)\n- 동영상 문제는 홈페이지를 확인하라고 되어있다. \n- 기타 등등\n\n#### ***다른 개발자들은 어떻게 했을까?***\n<br/> \n\n![](images/20250204_090812.png)\n\n일단 막막한 마음을 조금이라도 해소하기 위해서 다른 앱들을 열어서 보기로 했다.\n무언가를 만들때 아이디어를 얻기 위해서 관련된 앱들을 순위에 상관없이 최대한 많이 받아서 사용해보는 편이다.\n\n![](images/20250204_101956.png)\n\n안드로이드 플레이스토어에서 `운전면허 학과시험`을 검색하면 많은 앱들이 나오는데 많은 앱을 다운받아서 사용해봤다.\n완성도가 높은 앱들도 많이 있었다. 과연 내가 더 완성도 높은 앱을 만들 수 있을까? (1등을 못하면 10등이라도 하자..^^)\n\n![](images/20250204_103153.png)\n\n내가 가장 많이 사용할거라고 생각한 연령대는 고등학교를 갓 졸업한 20살부터 20대 초반이라고 생각했다. 그래서 최초 다운로드 이후에 데이터를 최대한 사용하지 않는 안드로이드 APK의 압축을 풀어봤다. \n\n![](images/20250204_103934.png)\n\n많은 앱들이 데이터를 사용하지 않기 위함이거나 서버를 사용하지 않는 앱을 제작하기 위해서 문제은행, 이미지 동영상 등의 에셋을 앱에 포함시켜놓았는데\n과거의 문제은행으로 만들어져서 사용할수는 없지만 보통은 텍스트 파일 형태로 텍스트에 구분자를 두는 형식으로 데이터를 관리하고 있었다.\n\n결국 남의 앱을 열어도 수동으로 변환했을 것 같은 데이터들이 많아서 변환에 대한 아이디어를 얻을 수 없었지만 적어도 내가 만들게될 앱은 누가 APK를 열어봐도 알아볼 수 없도록 암호화 후 복호화해서 사용해야겠다는 생각이 들었다.\n\n## 👋 마치며\n글이 너무 길어지는 것 같아서 실제 데이터를 만들어내는 작업에 대한 내용은 다음 포스팅에서 이어가도록 하겠다."},{"excerpt":"✋ 들어가며 처음 개발자로 일하기 시작했을때는 주로 WebView 기반의 Android, iOS 모바일 하이브리드 앱을 주로 개발하다가 시간이 흐를수록 모바일 개발은 손을 떼고 Java 기반의 웹어플리케이션을 주로 개발해왔다.\n지금은 DevOps를 주로 다루고 있지만 가볍게(?) 나만의 서비스를 만들어보면 어떨까 하는 생각이 들어서 무작정 시작해보려고 한…","fields":{"slug":"/create-app-what-to-make-how-to-make-it/"},"frontmatter":{"date":"January 24, 2025","title":"무작정 시작해보는 앱 만들기 (무엇을 만들까?)","tags":["에세이","앱만들기"],"emoji":"🦴","series":"💰 무작정 모바일 앱 출시하기"},"rawMarkdownBody":"\n## ✋ 들어가며\n\n처음 개발자로 일하기 시작했을때는 주로 WebView 기반의 Android, iOS 모바일 하이브리드 앱을 주로 개발하다가 시간이 흐를수록 모바일 개발은 손을 떼고 Java 기반의 웹어플리케이션을 주로 개발해왔다.\n지금은 DevOps를 주로 다루고 있지만 가볍게(?) 나만의 서비스를 만들어보면 어떨까 하는 생각이 들어서 무작정 시작해보려고 한다. \n\n## 🫗 역사 속으로 사라진 나의 앱(들)\n\n나만 아는 역사이긴 하지만 이미 20~30개 정도의 앱을 출시해본 경험이 있다. 지금은 계정이 2개나 정지당하고 앱 역시 역사 속으로 사라졌다. \n\n#### ***첫번째 시도***\n\n나의 첫번째 시도는 2017년, 그 당시 표현으로 '똥을 눌때도 들어오는 돈'을 벌기위해서\n과감하게 안드로이드 개발자 계정을 구매했지만 아이디어가 없었던 나는 일단 라이센스에 문제가 없는 오픈소스를 찾아서 이름만 바꾼 앱을 출시했다.\n\n신기하게도 만드는데 1시간도 걸리지 않은 앱이 첫 달에 400원 정도의 수익이 생겼다. \n\n이렇게 10개를 찍어내면 4000원, 100개를 찍어내면 40,000원이 아닌가? \n근거가 하나도 없는 자신감이 생기고 희망이 보이기 시작했다. \n\n> 💣 ***이럴수가?***\n> <br/><br/>\n> 1개를 출시 했을때 400원이었던 수익이 10개를 출시 했더니 그대로 400원이었다.\n\n~~이렇게 조기 은퇴의 꿈이 좌절됐다.~~\n\n#### ***N번째 시도 (부끄러운 과거..)***\n\n2018년에는 지금까지 평생 만들었던 앱 중에서 가장 큰 수익을 안겨주었던 앱이 만들어졌다. (약 1만 다운로드)\n\n이때는 취미로 사진 동호회를 운영하면서 사진을 좋아하는 많은 사람들을 만나고 고민을 나누던 시기였다.\n사진을 좀 잘 찍으시는 분들의 최대 고민은 `내가 인스타그램에 올린 사진을 누군가 허락없이 도용한다는 것`이었다.\n\n인스타그램은 사진 저장이 막혀있는데 어떤 방식으로 다운로드를 하는지 궁금증이 생겼다.\n\n> ⚠️ 아니 이렇게 불편하게 남에 사진을 다운받는다고?\n\n당시 다른 앱이나 서비스들은 인스타그램 앱에서 공유하기 버튼을 눌러서 주소를 복사한 후 다운로드 앱으로 들어가서 붙여넣으면 사진이 저장되는 방식이었다.\n그래서 경쟁 앱보다 편안하게 남에 사진을 다운받을 수 있는 앱을 제작했다.\n\n내가 만들었던 앱을 실행하면 인스타그램 모바일 화면이 WebView 형태로 출력되고 Javascript를 이용해서 사진 위에 저장 버튼을 위치시켰다.\n인스타그램의 화면과 똑같은데 저장버튼이 추가되었던 것이다. \n\n꼬린내 나는 앱 중에서는 가장 편한 사용자 경험을 제공했던 것 같다.\n그래서 그런지 다운로드 수가 점점 늘어가고 1만 다운로드를 넘어섰을 때 누군가의 신고로 앱이 삭제됐다.\n\n![](images/20250124_171458.png)\n\n이후에도 정신을 못차리고 꼬린내 나는 앱들을 계속 제작했다. (e.g. WebView 기반으로 제작 후 승인이 나면 유튜브 다운로더로 둔갑해버리는 그런 앱들..)\n\n당연한 결과지만 그렇게 잦은 신고를 당하고 잦은 이의 신청을 하면서 첫번째 개발자 계정이 정지됐다.\n\n#### ***N+1번째 시도***\n\n이때는 오픈된 데이터를 어떻게 활용할지에 대한 관심이 많은 시기였다.\n가장 먼저 나의 관심을 끌었던 데이터는 도로교통공단에서 제공하는 '운전면허 학과시험 문제은행'이었다.\n운전면허 학과시험은 지금도 동일하게 공개된 1000문제 중에서 유형별로 총 40문제가 똑같이 출제되고 있다.\n\n그래서 공개된 데이터를 기반으로 운전면허 학과시험 모의고사 앱을 제작했는데 완성도가 좋지 않은 앱인데도 생각보다는 수요가 있었다.\n\n이렇게 또 희망이 보이기 시작하고 똑같은 UI를 활용해서 정보처리기사, 컴퓨터활용, 공인중개사 등 각종 기출문제 모의고사 앱을 제작해왔는데\n어느 순간 자격증 시험이 모두 CBT로 변경되면서 기출문제의 개념이 사라지고 업데이트하지 못한 앱들은 열기가 식기 시작했다.\n\n그러면서 나의 열정도 없어져버리고 관리하지 못한 개발자 계정은 두번째 정지를 맞이했다.\n\n![](images/20250124_171057.png)\n\n\n## 👀 그래서 뭘 만들건데?\n\n글이 너무 길어졌지만 결론은 아직도 도로교통공단에서 공개하고 있는 '운전면허 학과시험 문제은행'을 활용해서 다시 한번 운전면허 학과시험 모의고사 앱을 제작해보려고 한다.\n과거에는 안드로이드 플레이스토어에만 출시했지만 이번에는 안드로이드와 iOS에 모두 출시를 목표로 한번도 사용해보지 않은 [Flutter↗](https://flutter.dev/)를 활용할 예정이다.\n\n## 👋 마치며\nFlutter의 'F'도 모르지만 그렇게 깊게 공부할 생각은 아직 없다. (어쩔 수 없는 이 ~~불량한 태도~~)\n<br/>그저 이 시리즈의 제목처럼 일단 해보자는 마음으로 무작정 시작해보겠다."},{"excerpt":"✋ 들어가며 지금 보고있는 이 글의 시리즈에서 알 수 있듯이 얼마전까지는 Jetbrains에서 만든 문서도구인 Writerside↗로 블로그를 운영했었는데 \n정말 좋은 도구임은 틀림 없지만 블로그와는 좀 맍지 않는 부분이 많이 있었다. (아마도 API 문서 등에 적합할 것 같다.)\n그리하여 Gatsby를 이용한 블로그를 만들게 되었다. ☑️ Gatsby는 …","fields":{"slug":"/gatsby-theme-github-pages/"},"frontmatter":{"date":"January 24, 2025","title":"Gatsby 테마 설치 후 Github Pages에 배포하기 (feat. gatsby-starter-rundevelrun)","tags":["github-pages","blog","gatsby"],"emoji":"💬","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n## ✋ 들어가며\n지금 보고있는 이 글의 시리즈에서 알 수 있듯이 얼마전까지는 Jetbrains에서 만든 문서도구인 [Writerside↗](https://www.jetbrains.com/ko-kr/writerside/)로 블로그를 운영했었는데 \n정말 좋은 도구임은 틀림 없지만 블로그와는 좀 맍지 않는 부분이 많이 있었다. (아마도 API 문서 등에 적합할 것 같다.)\n그리하여 Gatsby를 이용한 블로그를 만들게 되었다.\n\n> ☑️ Gatsby는 React와 GraphQL을 사용하여 Node.js 위에 구축된 오픈 소스 정적 사이트 생성기 입니다.\n> <br/><br/>\n> 출처 : [위키백과↗](https://en.wikipedia.org/wiki/Gatsby_(software))\n\n## 🤔 왜 Gatsby를 선택했나?\n\n1. Markdown 형식의 포스트 (Markdown, JSX가 포함된 MDX)\n   - Writerside에서 작성한 글들을 최소한의 수정으로 사용하기 위함\n2. Adsense 등 2500개 이상의 플러그인\n3. 필자가 더 알아가고 싶은 React 기반 \n4. 많은 수의 레퍼런스\n5. 블로그를 운영하면서 원하는건 모두 할 수 있을 것 같은 자유도 (GraphQL 등)\n\n## 🌱 테마 제작기\n\n> ☑️ 제작한 테마는 누구나 사용할 수 있도록 [Github↗](https://github.com/rundevelrun/gatsby-starter-rundevelrun)에 공개되어있다.\n\n편하게 사용할 수 있도록 [devHudi↗](https://github.com/devHudi/gatsby-starter-hoodie)님이 공개해주신 소스를 바탕으로 수정을 진행했다.\n\n1. SEO 최적화 진행\n2. Adsense 광고\n   - 본문 상/하단, 리스트 사이, ToC 하단에 광고 표시\n3. 본문 Emoji 영역과 Title 분리\n4. UI 변경\n5. 마이너한 버그 수정\n\n\n## 🏗️ 테마 설치하기\n\n## ☀️ 테스트 환경\n> - NodeJS v22.13.0\n> - yarn 1.22.22\n\n#### ***NodeJS 설치***\n자신의 OS에 맞는 [NodeJS↗](https://nodejs.org/ko/download) 설치\n\n#### ***Yarn 설치***\n```shell\nnpm install -g yarn\n```\n\n#### ***gatsby-cli 설치***\n```shell\nyarn global add gatsby-cli\n```\n\n#### ***gatsby-starter-rundevelrun 테마 설치***\n```shell\ngatsby new your-blog-name https://github.com/rundevelrun/gatsby-starter-rundevelrun.git\n```\n\n## 🤖 구동하기\n\n#### ***의존성 패키지 설치***\n```shell\ncd your-blog-name\nyarn install\n```\n\n#### ***구동***\n구동 후 `http://localhost:8000`으로 접속한다.\n```shell\nyarn develop\n```\n\n## 👨‍💻 사용자화\n`blog-config.js`의 내용을 자신에게 맞게 수정한다.\n\n```javascript\nmodule.exports = {\n  title: \"YOUR:BLOG:NAME\",    // SEO Blog title\n  headerTitle: \"YOUR:<em style='color:#ed6c02'>BLOG</em>:NAME\", // Logo 1\n  headerSubTitle: \"<em style='color:#ed6c02'>YOUR</em>:BLOG:<em style='color:#ed6c02'>NAME</em>\", // Logo 2\n  copyright: \"©YOUR:BLOG:NAME\", // copyright in footer\n  author: \"YOUR:NAME\",  // Your Name\n  description: \"Hi, Nice to meet you !\",  // description\n  siteUrl: \"https://6developer.com/\", // Your Site URL\n  links: {\n    github: \"https://github.com/rundevelrun\",\n    ...\n  },\n  giscus: {\n    ...\n  },\n  adsense: { \n    ...\n  }\n}\n```\n\n1. title : SEO에서 사용할 블로그명\n2. headerTitle : 블로그에 표시될 제목 (HTML 태그 가능)\n3. headerSubTitle : 블로그에 표시될 부제목\n   - HTML 태그 가능\n   - 옵션 값이며 있는 경우 블로그의 로고 영역이 5초마다 바뀐다.\n4. copyright : Footer 영역에 표시될 저작권 표시 이름\n5. author : 루트 페이지와 포스트 하단에 표시되는 작성자 이름\n6. description : 루트 페이지와 포스트 하단에 표시되는 작성자 설명\n7. siteUrl : 현재 블로그 URL\n8. links : 루트 페이지와 포스트 하단에 표시되는 Icon의 링크 목록\n9. giscus : 댓글 기능을 사용하기 위한 Giscus 정보\n10. adsense : 광고 기능을 사용하기 위한 Adsense 정보\n\n\n## 📝 포스트 작성하기\n1. `contents/posts` 폴더에 게시글 파일 생성 (두가지 방법)\n   - pathname으로 사용할 이름의 폴더를 만들고 하위에 'index.md'를 생성\n   - pathname으로 사용할 이름으로 `*.md` 파일 생성\n2. frontmatter 작성\n   ```yaml\n   ---\n   emoji: \"🚀\"\n   title: \"어떻게 시작할까요?\"\n   date: 2025-01-19 13:53:00\n   update: 2025-01-19 13:53:00\n   tags:\n      - rundevelrun\n      - howto\n   series: \"Gatsby 블로그 시작하기\"\n   ---\n   ```\n\n## 🚀 Github Pages 배포하기\nGatsby를 인수한 [Netlify](https://app.netlify.com/)를 아용한 아주 쉬운 배포 방법도 있지만 이 글에서는 Github Action을 이용하려고한다. \n필자의 경우 Git branch를 2개를 사용하고 있는데 `gatsby`에는 전체 소스가 올라가고 `main`에는 빌드된 소스가 배포된다.\n\n\n#### ***workflow 작성*** `.github/workflows/ci.yml`\n배포된 소스는 main에 push될 예정이므로 branchs 부분을 `main`으로 설정했다.\n```yaml\n# Simple workflow for deploying static content to GitHub Pages\nname: Deploy static content to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [\"main\"]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Single deploy job since we're just deploying\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Pages\n        uses: actions/configure-pages@v5\n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          # Upload entire repository\n          path: '.'\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n```\n\n#### ***배포 스크립트 작성*** `package.json`\n\n빌드된 정적 소스를 `main`에 배포하는 스크립트\n```json\n...\n\"scripts\": {\n   ...\n   \"deploy\": \"gatsby build && gh-pages -d public -b main\"\n},\n```\n\n#### ***배포 브랜치 최신화***\n배포 브랜치(현재 글에서는 main)에 위에서 작성한 `ci.yml`이 없는 상태라면 Github Action이 동작하지 않기 때문에 먼저 소스를 최신화한다.\n\n#### ***배포***\n`main` 브랜치에 빌드된 소스 push가 이루어지고 이후 `ci.yml`의 파이프라인이 동작한다.\n```shell\nyarn deploy\n```\n\n## 👋 마치며\n작성하다보니 너무 긴 글을 작성한 것 같다. 다음엔 조절해야지"},{"excerpt":"☀️ 테스트 환경 node v20.16.0 yarn 1.22.22 react ^18.2.0 ✋ 들어가며 지난 포스팅에서는 EC2에 올라간 SpringBoot 기반 웹어플리케이션에서 Presigned URL을 발급받는 과정을 알아보았다.\n이번에는 발급받은 Presigned URL을 사용해서 Client(React)에서 S3로 파일을 직접 업로드/다운로드 하는…","fields":{"slug":"/presigned-url-s3-upload-react/"},"frontmatter":{"date":"January 21, 2025","title":"React에서 S3 Presigned URL을 이용한 파일 업로드/다운로드","tags":["aws","s3","presigned-url","react"],"emoji":"⬆️","series":"📂 AWS S3 Presigned URL"},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - node v20.16.0\n> - yarn 1.22.22\n> - react ^18.2.0\n\n## ✋ 들어가며\n\n지난 포스팅에서는 EC2에 올라간 SpringBoot 기반 웹어플리케이션에서 Presigned URL을 발급받는 과정을 알아보았다.\n이번에는 발급받은 Presigned URL을 사용해서 Client(React)에서 S3로 파일을 직접 업로드/다운로드 하는 방법에 대해서 작성해보려고 한다.\n\n\n## 🛠️ Presigned URL을 이용한 파일 업로드/다운로드\n\n#### ***파일 업로드***\n```tsx\nimport axios from \"axios\";\n```\n```tsx\n// File Object와 Presigned URL을 파라미터로 받아서 파일을 업로드\nconst uploadFile= async (file: File, presignedUrl: string) => {\n  try {\n    await axios.put(presignedUrl, file, {\n      headers: {\n        'Content-Type': file.type,\n      },\n    });\n  } catch (e) {\n    console.error(e);\n  }\n}\n```\n\n#### ***파일 다운로드***\n\n```tsx\nimport axios from \"axios\";\n```\n```tsx\n// Presigned URL을 파라미터로 받아서 파일을 다운로드\nconst downloadFile = async (presignedUrl: string) => {\n  const response = await fetch(presignedUrl);\n  const blob = await response.blob();\n  const url = window.URL.createObjectURL(blob);\n  const link = document.createElement('a');\n  link.href = url;\n  link.download = 'file';\n  document.body.appendChild(link);\n  link.click();\n  document.body.removeChild(link);\n  window.URL.revokeObjectURL(url);\n}\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 OpenJDK 17.0.2   Gradle 8.0.2     Spring Boot 3.0.5 ✋ 들어가며 이번 포스팅 에서는 EC2에 올라간 SpringBoot 기반 웹어플리케이션에서 Presigned URL을 발급받는 과정을 작성해보려고 한다.\n현재 작성중인 Series의 첫번째 포스팅은 EC2에 S3 Bucket 접근 권한을 부여하는 …","fields":{"slug":"/presigned-url-s3-upload-springboot/"},"frontmatter":{"date":"January 21, 2025","title":"SpringBoot에서 S3 Presigned URL 발급받기","tags":["aws","s3","presigned-url","springboot"],"emoji":"🔐","series":"📂 AWS S3 Presigned URL"},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - OpenJDK 17.0.2  \n> - Gradle 8.0.2    \n> - Spring Boot 3.0.5\n\n## ✋ 들어가며\n\n이번 포스팅 에서는 EC2에 올라간 SpringBoot 기반 웹어플리케이션에서 Presigned URL을 발급받는 과정을 작성해보려고 한다.\n현재 작성중인 Series의 첫번째 포스팅은 EC2에 S3 Bucket 접근 권한을 부여하는 과정을 작성했었다.\n\n이미 EC2에 S3 Bucket 접근 권한을 부여했기 때문에 이 글에서는 Credentials(Access key, Secret key)에 대한 내용은 언급하지 않는다.\n\n## ❓ Presigned URL이란?\n\n> ☑️ Presigned URL은 모두 유추 할 수 있겠지만 S3 Bucket에 파일을 업로드/다운로드할 수 있는 미리 서명된 URL으로 해당 URL을 통해서만 파일에 접근할 수 있다.\n\n\n## 🛠️ Presigned URL 발급받기\n\n#### ***build.gradle***\n\n먼저 AWS SDK를 사용하기 위해서 아래와 같이 의존성을 추가해준다.\n\n```gradle\ndependencies {\n    //  AWS\n    implementation 'com.amazonaws:aws-java-sdk-s3:1.12.770'\n    implementation 'com.amazonaws:aws-java-sdk-core:1.12.770'\n    implementation 'com.amazonaws:aws-java-sdk-sts:1.12.770'\n}\n``` \n\n#### ***config 파일 수정***\n\n`application.properties` 또는 `application.yml` 파일에 S3 Bucket 이름을 추가해준다.\n\n- application.properties\n   ```properties\n   cloud.aws.s3.bucket=S3_BUCKET_NAME\n   ```\n- application.yml\n   ```yml\n   cloud:\n     aws:\n       s3:\n         bucket: S3_BUCKET_NAME\n   ```\n\n#### ***Presigned URL 발급받기***\n\n- 업로드용 Presigned URL 발급\n  ```java\n  @Value(\"${cloud.aws.s3.bucket}\")\n  private String bucket;\n\n  AmazonS3 s3Client;\n  ```\n  ```java\n  String filePath = \"upload/test.jpg\"; // 업로드할 파일 경로\n  \n  // S3 Client 생성\n  s3Client = AmazonS3ClientBuilder\n            .standard()\n            .withRegion(Regions.AP_NORTHEAST_2) // Region 설정\n            .build();    \n  \n  // Pre-Signed URL 만료 시간 설정 (10분 후)\n  Date expiration = new Date();\n  long expTimeMillis = expiration.getTime();\n  expTimeMillis += TimeUnit.MINUTES.toMillis(10);\n  expiration.setTime(expTimeMillis);\n  \n  // Upload Pre-Signed URL Generate (PUT Method)\n  GeneratePresignedUrlRequest generatePresignedUrlRequest =\n            new GeneratePresignedUrlRequest(bucket, filePath)\n                    .withMethod(HttpMethod.PUT)\n                    .withExpiration(expiration);\n  URL url = s3Client.generatePresignedUrl(generatePresignedUrlRequest);\n  \n  // 발급된 업로드용 Pre-Signed URL\n  String putPreSignedUrl = url.toString();\n  ```\n\n\n- 다운로드용 Presigned URL 발급\n  ```java\n  @Value(\"${cloud.aws.s3.bucket}\")\n  private String bucket;\n\n  AmazonS3 s3Client;\n  ```\n  ```java\n  String filePath = \"upload/test.jpg\"; // 다운로드할 파일 경로t\n  \n  // S3 Client 생성\n  s3Client = AmazonS3ClientBuilder\n            .standard()\n            .withRegion(Regions.AP_NORTHEAST_2) // Region 설정\n            .build();    \n\n  // Pre-Signed URL 만료 시간 (10분 후)\n  Date expiration = new Date();\n  long expTimeMillis = expiration.getTime();\n  expTimeMillis += TimeUnit.MINUTES.toMillis(10);\n  expiration.setTime(expTimeMillis);\n  \n  // Download Pre-Signed URL Generate (GET Method)\n  GeneratePresignedUrlRequest generatePresignedUrlRequest =\n            new GeneratePresignedUrlRequest(bucket, filePath)\n                    .withMethod(HttpMethod.GET)\n                    .withExpiration(expiration);\n  URL url = s3Client.generatePresignedUrl(generatePresignedUrlRequest);\n  \n  // 발급된 다운로드용 Pre-Signed URL\n  String putPreSignedUrl = url.toString();\n  ```\n\n\n## 👋\nSpringBoot에서 S3Client를 사용해서 Presigned URL을 발급받는 방법에 대해서 알아보았다.\n다음 포스팅에서는 React에서 발급받은 Presigned URL을 사용해서 파일을 업로드/다운로드 하는 방법에 대해서 작성해보려고 한다.\n"},{"excerpt":"☀️ 테스트 환경 OpenJDK 17.0.2 Gradle 8.0.2 Spring Boot 3.0.5 ✋ 들어가며 @Scheduled Annotation으로 정해진 시간에 수행되는 메소드를 구현했다.\n해당 Annotation을 사용하는 메소드 내에서 정상 여부의 로그를 남기기 위해서는 똑같은 소스를 매번 작성해야하는 문제가 발생했다. 그리하여 @Schedul…","fields":{"slug":"/spring-custom-annotation/"},"frontmatter":{"date":"January 20, 2025","title":"Spring Custom Annotation 만들기 (Feat. AOP)","tags":["spring","springboot","aop"],"emoji":"🌱","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - OpenJDK 17.0.2\n> - Gradle 8.0.2\n> - Spring Boot 3.0.5\n\n## ✋ 들어가며\n_@Scheduled_ Annotation으로 정해진 시간에 수행되는 메소드를 구현했다.\n해당 Annotation을 사용하는 메소드 내에서 정상 여부의 로그를 남기기 위해서는 똑같은 소스를 매번 작성해야하는 문제가 발생했다.\n\n그리하여 _@Scheduled_ Annotation을 커스텀하고 AOP를 활용하여 해당 Annotation을 사용할때 로그를 남기도록 구현해보고자한다.\n\n#### ***문제의 소스***\n\n> ⚠️ ***로그를 남기기 위해서 매번 같은 소스가 작성되어 있다.***\n> - logService.insertLog(result);\n\n```Java\n@Component\npublic class ScheduledComponent {\n    @Scheduled(cron= \"0 0 0 * * *\")\n    public Map<String, Object> scheduled1() {\n        ...\n        // 로그 저장\n        logService.insertLog(result);\n        ...\n        return result;\n    }\n    @Scheduled(cron= \"0 0 1 * * *\")\n    public int scheduled2() {\n        ...\n        // 로그 저장\n        logService.insertLog(result);\n        ...\n        return result;\n    }\n    ...\n}\n```\n\n## 🧰 AOP를 통한 Custom Annotation 처리\n\n#### ***CustomScheduled.java***\n1. @Target : Annotation이 적용될 위치\n    - @CustomScheduled를 메소드에 적용하기 위해서 `ElementType.METHOD` 사용\n2. @Retention : Annotation이 적용될 범위\n    - 런타임까지 유지되는 Annotation을 정의하기 위해서 `RetentionPolicy.RUNTIME` 사용 \n3. @Scheduled : Scheduled Annotation과 같은 동작을 위해서 사용\n```Java\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Scheduled\npublic @interface CustomScheduled {\n    String cron() default \"\";\n}\n```\n\n#### ***CustomScheduledAspect.java*** ###\n1. AOP가 구현된 클래스에는 *@Aspect* Annotation을 사용한다. \n2. 해당 클래스의 메소드에는 AOP를 적용할 패턴 혹은 관심사를 구현할 수 있다.\n    - @Before : 패턴이 실행되기 전에 동작\n    - @After : 패턴이 실행된 이후에 동작\n    - @Around : 패턴이 실행되기 전, 후 모두 동작 (실행결과 반환을 위해 반환 값은 Object)\n3. 예제에서는 *@CustomScheduled*가 사용된 클래스명, 메소드명 그리고 결과를 로그 테이블에 저장하고 있다 \n```Java\n@Aspect\n@Component\npublic class CustomScheduledAspect {\n\n    @Around(\"@annotation(customScheduled)\")\n    public Object handleWsfScheduled(ProceedingJoinPoint joinPoint, CustomScheduled customScheduled) throws Throwable {\n\n        MethodSignature signature = (MethodSignature) joinPoint.getSignature();\n\n        // 실행\n        Object result = joinPoint.proceed();\n\n        Map<String, Object> logParam = new HashMap<String, Object>();\n        logParam.put(\"className\", joinPoint.getSignature().getDeclaringTypeName());\n        logParam.put(\"methodName\", joinPoint.getSignature().getName());\n        logParam.put(\"result\", result.toString());\n\n        // 배치 로그 저장\n        logService.insertLog(param);\n\n        return result;\n\n    }\n}\n```\n\n#### ***Custom Annotation 사용***\n> ☑️ *@CustomScheduled*를 사용하면 로그 관련 처리는 AOP에서 하고 있기 때문에 메소드에는 비즈니스 로직 수행 및 결과 반환에 대한 소스만 작성되어 있다. \n\n```Java\n@Component\npublic class ScheduledComponent {\n    @CustomScheduled(cron= \"0 0 0 * * *\")\n    public Map<String, Object> scheduled1() {\n        ...\n        return result;\n    }\n    @CustomScheduled(cron= \"0 0 1 * * *\")\n    public Map<String, Object> scheduled2() {\n        ...\n        return result;\n    }\n    ...\n}\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 node v20.16.0 yarn 1.22.22 react ^18.2.0 ⛔ ERROR 어제까지는 잘 되던게 갑자기 안됨 yarn.lock 파일삭제하고 다시  실행 후 를 수행하면 아래와 같은 오류가 발생한다. ❓ 왜 설지된 패키지(@types/react) 버전이 이상하다 문제의 패키지 버전을 으로 명시해놓고 사용하는데  이후 생성된 ya…","fields":{"slug":"/react-error-slider-cannot-be-used-as-a-jsx-component/"},"frontmatter":{"date":"January 20, 2025","title":"ERROR. 'Slider' cannot be used as a JSX component.","tags":["react","error"],"emoji":"️🌋","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - node v20.16.0\n> - yarn 1.22.22\n> - react ^18.2.0\n\n## ⛔ ERROR\n\n#### ***어제까지는 잘 되던게 갑자기 안됨***\n- _yarn.lock_ 파일삭제하고 다시 `yarn install` 실행 후 `build`를 수행하면 아래와 같은 오류가 발생한다.\n\n```javascript\nerror TS2322: Type '{ children: Element[]; dots: boolean; infinite: boolean; speed: number; slidesToShow: number; slidesToScroll: number; autoplay: boolean; autoplaySpeed: number; centerMode: boolean; swipeToSlide: boolean; ... 5 more ...; ref: RefObject<...>; }' is not assignable to type 'Readonly<Settings>'.\n  Types of property 'appendDots' are incompatible.\n    Type '(dots: ReactNode) => JSX.Element' is not assignable to type '(dots: ReactNode) => Element'.\n      Types of parameters 'dots' and 'dots' are incompatible.\n        Type 'import(\"~~\").ReactNode' is not assignable to type 'React.ReactNode'.\n          Type 'bigint' is not assignable to type 'ReactNode'.\n\n        <Slider ref={sliderRef} {...settings}>\n```\n\n```javascript\nerror TS2786: 'Slider' cannot be used as a JSX component.\nIts type 'typeof Slider' is not a valid JSX element type.\nTypes of construct signatures are incompatible.\nType 'new (props: Settings) => Slider' is not assignable to type 'new (props: any, deprecatedLegacyContext?: any) => Component<any, any, any>'.\nProperty 'refs' is missing in type 'Slider' but required in type 'Component<any, any, any>'.\n\n        <Slider ref={sliderRef} {...settings}>\n```\n\n## ❓ 왜\n\n#### ***설지된 패키지(@types/react) 버전이 이상하다***\n- 문제의 패키지 버전을 `^18.2.43`으로 명시해놓고 사용하는데 `yarn install` 이후 생성된 _yarn.lock_ 파일에는 `19.0.1`로 설치가 되었다.\n\n```json\n// package.json\n\n...\n\"devDependencies\": {\n  \"@types/react\": \"^18.2.43\",\n...\n```\n\n```json\n// yarn.lock\n\n...\n\"@types/react@*\", \"@types/react@>=16\":\n  version \"19.0.1\"\n  resolved \"https://~~~\"\n  integrity ~~~\n  dependencies:\n    csstype \"^3.0.2\"\n...\n```\n\n#### ***하위 의존성 패키지 문제***\n- _package.json_ 에 명시되어있는 몇개의 패키지가 하위 의존성 패키지로 _@types/react_ 의 버전을 `19.0.1`로 불러오고 있었다. 아래 두가지 패키지가 문제였다.\n\n```JSON\n// package.json\n\n...\n\"dependencies\": {\n  \"@mui/material\": \"^5.15.0\",        \n},\n\"devDependencies\": {\n  \"@types/react-slick\": \"^0.23.13\" ,\n...\n```\n\n## ✅ 해결\n\n#### ***하위 패키지 버전 명시***\n- 여러 패키지가 동일한 의존성을 가질 때 버전을 일관되게 유지할 수 있도록 [resuolutions↗](https://classic.yarnpkg.com/lang/en/docs/selective-version-resolutions/)를 사용 할 수 있다.\n\n```JSON\n// package.json\n\n...\n\"resolutions\": {\n  \"@types/react\": \"^18.2.43\",\n}\n```\n\n## 👋 마치며\n별게 다 속을 썩인다.\n\n"},{"excerpt":"☀️ 테스트 환경 PostgreSQL 16.1 (Amazon Aurora) Amazon Aurora↗는 MySQL 및 PostgreSQL과 호환되는 완전 관리형 관계형 데이터베이스 엔진이다. ✋ 들어가며 database를 통으로 날려버리기 위해서 문제의 쿼리를 실행하다가 오류를 발견했다.\n없어질 건 없어져야 하기 대문에 세션을 종료하고 쿼리를 실행하는걸로 …","fields":{"slug":"/postgresql-session-kill/"},"frontmatter":{"date":"January 20, 2025","title":"PostgreSQL 세션 정보 확인 및 종료","tags":["postgresql"],"emoji":"💣","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - PostgreSQL 16.1 (Amazon Aurora)\n>   - [Amazon Aurora↗](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html)는 MySQL 및 PostgreSQL과 호환되는 완전 관리형 관계형 데이터베이스 엔진이다.\n\n## ✋ 들어가며\ndatabase를 통으로 날려버리기 위해서 문제의 쿼리를 실행하다가 오류를 발견했다.\n없어질 건 없어져야 하기 대문에 세션을 종료하고 쿼리를 실행하는걸로 해결.\n\n#### ***문제의 쿼리***\n```SQL\ndrop database _YOUR_DATABASE_NAME_;\n```\n\n#### ***오류 내용***\n```Bash\n[55006] ERROR: database \"_YOUR_DATABASE_NAME_\" is being accessed by other users\nDetail: There are `n` other sessions using the database.\n```\n\n\n## 🧹 세션 정보 확인\npg_stat_activity 테이블에서 접속중인 세션 정보를 확인한다.\n\n```SQL\nselect pid\n    , usename\n    , application_name \n    , client_addr\nfrom pg_stat_activity\nwhere datname = '_YOUR_DATABASE_NAME_';\n```\n\n\n## 🧲 세션 종료\n\n#### ***단건 종료 처리***\n```SQL\nselect pg_terminate_backend(pid);\n```\n\n#### ***일괄 종료 처리***\n```SQL\nselect pg_terminate_backend(pid)\nfrom pg_stat_activity\nwhere datname = '_YOUR_DATABASE_NAME_';\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) PostgreSQL 17.2 ✋ 들어가며 AWS EC2 환경에 PostgreSQL 17 버전을 설치했는데 공식 문서↗를 보고 설치하려 했으나 생각처럼 순탄하게 되지 않아서 수동 설치를 하기로 했다. 💾 PostgreSQL 다운로드 다운로드 링크 확인 여기↗에서 원하는 버전을 선택하고 postgre…","fields":{"slug":"/amazon-linux-postgresql-17-install/"},"frontmatter":{"date":"January 20, 2025","title":"Amazon Linux에 PostgreSQL 수동 설치","tags":["aws","ec2","amazon-linux","linux","postgresql"],"emoji":"🗄️","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - PostgreSQL 17.2\n\n## ✋ 들어가며\nAWS EC2 환경에 PostgreSQL 17 버전을 설치했는데 [공식 문서↗](https://www.postgresql.org/download/linux/redhat/)를 보고 설치하려 했으나 생각처럼 순탄하게 되지 않아서 수동 설치를 하기로 했다.\n\n## 💾 PostgreSQL 다운로드\n\n#### ***다운로드 링크 확인***\n[여기↗](https://ftp.postgresql.org/pub/source/)에서 원하는 버전을 선택하고 postgresql-[_VERSION_].tar.gz의 링크를 복사한다. (EC2에 직접 업로드 하는 경우는 다운로드 후 원하는 위치에 업로드한다.)\n\n#### ***필수 패키지 설치***\n```Shell\nsudo yum -y install gcc gcc-c++ make autoconf readline readline-devel zlib zlib-devel openssl openssl-devel gettext gettext-devel python python-devel bison flex perl\n```\n\n#### ***다운로드 및 압축해제***\n```Shell\nsudo wget https://ftp.postgresql.org/pub/source/v17.2/postgresql-17.2.tar.gz\n```\n\n```Shell\nsudo tar zxvf postgresql-17.2.tar.gz\n```\n\n\n## 🚀 PostgreSQL 설치\n미리 설치 폴더와 data 폴더를 생성해둔다. (e.g. /postgresql-17.2, /postgresql-17.2/data) \n\n#### ***소스 코드 빌드***\n```Shell\nsudo ./configure --prefix=/postgresql-17.2 --with-openssl --sysconfdir=/postgresql-17.2/data\n```\n\n_configure: error: ICU library not found_ 에러 발생시 _--without-icu_ 옵션을 추가한다.\n\n```Shell\nsudo ./configure --prefix=/postgresql-17.2 --with-openssl --sysconfdir=/postgresql-17.2/data --without-icu\n```\n\n#### ***컴파일 및 설치***\n```Shell\nsudo make\nsudo make install\n```\n\n## 💿 실행\n\n#### ***설치 폴더 소유권 변경***\nPostgreSQL은 sudo 권한으로 실행시 오류가 발생하기 떄문에 설치된 폴더의 소유권을 변경해준다.\n\n```Shell\nsudo useradd postgres\nsudo chown -R postgres:postgres /postgresql-17.2\n```\n\n``` Shell\n✔\ndrwxr-xr-x.  7 postgres postgres    68 Jan  2 04:53 postgresql-17.2\n...\n```\n\n#### ***환경 변수 설정***\n위에서 생성한 계정에 PATH를 설정한다.\n```Shell\nsudo su - postgres\nvi ~/.bashrc\n```\n```Shell\n...\nexport PATH=\"$PATH:/postgresql-17.2/bin\"\n...\n```\n\n#### ***초기화***\n```Shell\ninitdb -E utf-8 -D /postgresql-17.2/data\n```\n\n#### ***실행 및 확인***\n```Shell\npg_ctl -D /postgresql-17.2/data start\n```\n```Shell\npsql -d postgres\n```\n```Shell\n✔\npsql (17.2)\nType \"help\" for help.\n\npostgres=#\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 Jenkins 2.387.3 Amazon Linux 2023 (EC2)  ✋ 들어가며 젠킨스가 설치되어있는 서버와 실제로 어플리케이션이 배포될 대상 서버가 다른 경우에 SSH Agent 를 이용한 원격 배포 방법도 있겠지만 이 글에서는 Jenkins Node Agent를 활용한 방법을 다뤄보려고한다. 🔑 SSH Key 생성 및 복사 SSH…","fields":{"slug":"/jenkins-agent-node-ssh/"},"frontmatter":{"date":"January 20, 2025","title":"Jenkins Agent Node 설정하기","tags":["jenkins"],"emoji":"🤖","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Jenkins 2.387.3\n> - Amazon Linux 2023 (EC2) \n\n## ✋ 들어가며\n젠킨스가 설치되어있는 서버와 실제로 어플리케이션이 배포될 대상 서버가 다른 경우에 _SSH Agent_ 를 이용한 원격 배포 방법도 있겠지만 이 글에서는 Jenkins Node Agent를 활용한 방법을 다뤄보려고한다.\n\n\n## 🔑 SSH Key 생성 및 복사\nSSH를 활용해서 Agent를 시작하는 방식을 선택하려고 하기 떄문에 Agent가 동작할 서버에서 SSH Key를 생성한다. \n\n#### ***ssh-keygen***\n1. 놀랍게도 Enter의 입력만으로 SSH Key가 생성된다.\n```shell\ncd ~/.ssh\nssh-keygen -t rsa\n```\n```shell\n✔\nYour identification has been saved in /home/rundevelrun/.ssh/id_rsa.\nYour public key has been saved in /home/rundevelrun/.ssh/id_rsa.pub.\nThe key fingerprint is:\nSHA256:~~~\nThe key's randomart image is:\n+---[RSA 2048]----+\n| ...             |\n+----[SHA256]-----+\n```\n2. ~/.ssh 경로에 아래와 같은 파일들이 생성되었다면 성공이다.\n```shell\nls -al\n```\n```shell\n✔\n-rw------- 1 rundevelrun rundevelrun  401 Aug  5 05:45 authorized_keys\n-rw------- 1 rundevelrun rundevelrun 1679 Dec 12 02:22 id_rsa\n-rw-r--r-- 1 rundevelrun rundevelrun  438 Dec 12 02:22 id_rsa.pub\n```\n\n#### ***SSH Key 확인*** {id=\"ssh-key_1\"}\n*id_rsa* 파일을 열어서 내용을 확인하고 Jenkins 설정에 사용해야하기 때문에 복사해둔다.\n```shell\ncat id_rsa\n```\n```shell\n✔\n-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBA...\n\n\n-----END RSA PRIVATE KEY-----\n```\n\n## 🔐 Jenkins Credentials 설정\n\n#### ***등록 화면 접속***\n*Dashboard ➡ Jenkins 관리 ➡ Credentials  ➡  System ➡ Global credentials (unrestricted) ➡ Add Credentials*\n\n#### ***Credentials 생성***\n- Kind : SSH Username with private key\n- Scope : Global\n- ID : 젠킨스에서 사용하는 중복되지 않는 Credential ID\n- Description : 설명\n- Username : SSH Key를 생성한 계정\n- Private Key : `Enter directly`를 체크하고 위에서 복사한 SSH Key를 입력\n\n![](images/20241212_144903.png)\n\n## 💼 Jenkins Node 설정\n\n#### ***등록 화면 접속***\n*Dashboard ➡ Jenkins 관리 ➡ 노드 관리  ➡  New Node*\n\n노드명 입력 및 Permanent Agent에 체크하고 다음으로 넘어간다.\n![](images/20241212_150059.png)\n\n#### ***Node 생성***\n- Name : 노드명\n- Description : 설명\n- Number of executors : 노드에서 수행할 수 있는 동시 빌드 수\n- Remote root directory : Agent가 사용할 디렉토리\n- Labels : Jenkinsfile에서 사용할 Label\n- Launch method : label이 일치할때만 빌드가 실핼되도록 `Only build jobs...` 선택\n  - Host : 원격지 IP\n  - Credentials : 앞에서 등록한 Credential 선택\n  - Host Key Verification Strategy : 호스트 키 검증 전략 (검증하지 않는 전략을 사용하도록 설정)\n- Availability : Agent를 온라인 상태로 유지하도록 `Keep this agent online as...` 선택\n\n![](images/20241212_153946.png)\n\n## 📌 사용 예시 (Jenkinsfile Pipeline)\nAgent 설정을 마쳤으니 마지막으로 Jenkins Pipeline에서 어떻게 Agent를 사용하는지 확인할 차례다.\n\n#### ***Pipeline 전체에 적용***\n```Groovy\npipeline {\n    agent {\n        label 'rundevelrun_node'\n    }\n    ...\n}\n```\n\n#### ***특정 stage에만 적용***\n```Groovy\npipeline {\n    agent any\n    stages {\n        stage('rundevelrun stage') {\n            agent {\n                label 'rundevelrun_node'\n            }\n            steps {\n                // rundevelrun_node agent가 수행할 작업\n            }\n        }\n    }\n    ...\n}\n```\n\n## 👋 마치며\nJenkins Node Agent를 사용해서 원격 서버에 배포하는 방식을 기록해봤는데 곧  _SSH Agent_ 를 활용하는 방법도 기록해야겠다.\n\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) OpenJDK 17.0.2 ✋ 들어가며 AWS EC2 환경에 공식 문서↗를 보고 Jenkins를 설치했다.\n여기까지 찾아온 방문자에게는 고맙고 미안하지만 블로그 글 보다는 역시 공식 문서를 활용하는게 더 좋다. 🚀 Jenkins 다운로드 및 설치 ☑️ JDK가 설치되어있는 환경이라 생략되어있지만 먼…","fields":{"slug":"/amazon-linux-jenkins-install/"},"frontmatter":{"date":"January 20, 2025","title":"Amazon Linux에 Jenkins 설치하기","tags":["aws","ec2","amazon-linux","linux","jenkins"],"emoji":"🏗️","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - OpenJDK 17.0.2\n\n## ✋ 들어가며\nAWS EC2 환경에 [공식 문서↗](https://www.jenkins.io/doc/tutorials/tutorial-for-installing-jenkins-on-AWS/#downloading-and-installing-jenkins)를 보고 Jenkins를 설치했다.\n여기까지 찾아온 방문자에게는 고맙고 미안하지만 블로그 글 보다는 역시 공식 문서를 활용하는게 더 좋다.\n\n## 🚀 Jenkins 다운로드 및 설치\n\n> ☑️ JDK가 설치되어있는 환경이라 생략되어있지만 먼저 JDK를 꼭 설치해주자\n\n#### ***패키지 업데이트***\n```shell\nsudo yum update -y\n```\n\n#### ***Jenkins Repo 추가***\n```shell\nsudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo\n```\n\n#### ***패키지 설치를 활성화하기 위한 키 파일 Import***\n```shell\nsudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\n```\n\n#### ***Jenkins 설치*** {id=\"jenkins install\"}\n```shell\nsudo yum install jenkins -y\n```\n\n#### ***부팅시 시작되는 서비스 등록***\n```shell\nsudo systemctl enable jenkins\n```\n\n#### ***Jenkins 시작*** {id=\"jenkins start\"}\n```shell\nsudo systemctl start jenkins\n```\n\n#### ***Jenkins 상태 확인*** {id=\"jenkins status check\"}\n```shell\nsudo systemctl status jenkins\n```\n```shell\n✔\n● jenkins.service - Jenkins Continuous Integration Server\n   Loaded: loaded (/usr/lib/systemd/system/jenkins.service; enabled; vendor preset: disabled)\n   Active: active (running) since Wed 2024-12-18 01:26:13 UTC; 3h 22min ago\n...\n```\n\n## ⛔ 예상되는 오류\n필자는 운이 좋게도 한번에 시작이 되었지만 시작시 알 수 없는 오류에 시달릴 수도 있다. 시달리는 중이라면 왜 시달리고 있는지 상세 오류 내용을 확인해보자.\n\n```shell\nsudo journalctl -xe\n```\n\n#### ***jenkins: failed to find a valid Java installation***\n\n- 오류 내용\n```shell\n-- Unit jenkins.service has begun starting up.\njenkins[25524]: jenkins: failed to find a valid Java installation\nsystemd[1]: jenkins.service: main process exited, code=exited, status=1/FAILURE\nsystemd[1]: Failed to start Jenkins Continuous Integration Server.\n-- Subject: Unit jenkins.service has failed\n-- Defined-By: systemd\n-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel\n--\n-- Unit jenkins.service has failed.\n--\n-- The result is failed.\n```\n\n- 해결 : JAVA_HOME에 JDK 설치 경로를 설정해주면 끝.\n```shell\nsudo vi /usr/lib/systemd/system/jenkins.service\n```\n```shell\n...\n# The Java home directory. When left empty, JENKINS_JAVA_CMD and PATH are consulted.\nEnvironment=\"JAVA_HOME=[JDK 설치 경로]\"\n...\n```\n```shell\nsudo systemctl daemon-reload\n```\n\n#### ***Failed to bind to 0.0.0.0/0.0.0.0:8080***\n다른 프로세스에서 사용중인 포트인 경우 이런 오류를 만날 수 있고 다른 프로세스의 포트를 변경하든 젠킨스 포트를 변경하든 해야하는데 우리는 젠킨스 포트를 변경해보자.\n\n- 오류 내용\n```java\njenkins[16253]: Caused: java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:8080\njenkins[16253]: at Jenkins Main ClassLoader//org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:349)\njenkins[16253]: at Jenkins Main ClassLoader//org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:313)\njenkins[16253]: at Jenkins Main ClassLoader//org.eclipse.jetty.server.Server.lambda$doStart$0(Server.java:552)\njenkins[16253]: at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)\njenkins[16253]: at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\njenkins[16253]: at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)\njenkins[16253]: at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)\njenkins[16253]: at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\njenkins[16253]: at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\njenkins[16253]: at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)\njenkins[16253]: at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)\njenkins[16253]: at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\njenkins[16253]: at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\njenkins[16253]: at Jenkins Main ClassLoader//org.eclipse.jetty.server.Server.doStart(Server.java:548)\njenkins[16253]: at Jenkins Main ClassLoader//org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93)\njenkins[16253]: at Jenkins Main ClassLoader//winstone.Launcher.<init>(Launcher.java:190)\njenkins[16253]: Caused: java.io.IOException: Failed to start Jetty\njenkins[16253]: at Jenkins Main ClassLoader//winstone.Launcher.<init>(Launcher.java:194)\njenkins[16253]: at Jenkins Main ClassLoader//winstone.Launcher.main(Launcher.java:490)\njenkins[16253]: at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njenkins[16253]: at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njenkins[16253]: at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njenkins[16253]: at java.base/java.lang.reflect.Method.invoke(Method.java:568)\njenkins[16253]: at executable.Main.main(Main.java:335)\nsystemd[1]: jenkins.service: main process exited, code=exited, status=1/FAILURE\nsystemd[1]: Failed to start Jenkins Continuous Integration Server.\n-- Subject: Unit jenkins.service has failed\n-- Defined-By: systemd\n-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel\n--\n-- Unit jenkins.service has failed.\n--\n-- The result is failed.\n```\n\n- 해결\n    \n    ```shell\n    sudo vi /usr/lib/systemd/system/jenkins.service\n    ```\n    ```shell\n    ...\n    # Port to listen on for HTTP requests. Set to -1 to disable.\n    # To be able to listen on privileged ports (port numbers less than 1024),\n    # add the CAP_NET_BIND_SERVICE capability to the AmbientCapabilities\n    # directive below.\n    Environment=\"JENKINS_PORT=[변경할 포트]\"\n    ...\n    ```\n    ```shell\n    sudo systemctl daemon-reload\n    ```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) Docker 20.10.25 ✋ 들어가며 운영중인 시스템에서 Docker Root Directory를 변경해야하는 일이 생겨버렸다. 기본 설정의 Root Directory가 루트(/) 볼륨에 잡혀있어서 내부 정책상 다른 볼륨으로 옮겨가야했다. 💾 신규 디렉토리로 데이터 복사 기존 디렉토리 확인 도…","fields":{"slug":"/docker-root-directory-change/"},"frontmatter":{"date":"January 20, 2025","title":"Docker Root Directory 변경","tags":["aws","ec2","amazon-linux","linux","docker"],"emoji":"🐳","series":null},"rawMarkdownBody":"\n\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - Docker 20.10.25\n\n## ✋ 들어가며\n운영중인 시스템에서 Docker Root Directory를 변경해야하는 일이 생겨버렸다. 기본 설정의 Root Directory가 루트(/) 볼륨에 잡혀있어서 내부 정책상 다른 볼륨으로 옮겨가야했다.\n\n## 💾 신규 디렉토리로 데이터 복사\n\n#### ***기존 디렉토리 확인***\n도커 명령어를 이용해서 기존 디렉토리가 어디로 잡혀있는지 확인해보자. 필자의 경우 별도의 설정이 없었기에 기본 경로로 설정되어 있다.\n```shell\ndocker info\n```\n```shell\n✔\n...\nDocker Root Dir: /var/lib/docker\n...\n```\n\n#### ***신규 디렉토리 생성***\nDocker Root Directory로 사용할 신규 디렉토리를 생성해주자. 예제에서는 루트 볼륨과 분리되어있는 별도의 볼륨(/data)으로 진행했다.\n```shell\ncd /data\nmkdir docker\n```\n\n#### ***데이터 복사***\n운영중인 시스템이기 때문에 기존에 사용하던 디렉토리를 신규 디렉토리로 옮겨야했다.\n```shell\ncp -a /var/lib/docker/* /data/docker\n```\n\n## 🐳 data-root 설정\n\n#### ***첫번째 방법***\n_daemon.json_ 파일을 수정한다. (없으면 당황하지 말고 생성해주자)\n```shell\nsudo /etc/docker/daemon.json\n```\n```json\n{\n    \"data-root\": \"/data/docker/\",\n    ...\n}\n```\n\n\n#### ***두번째 방법***\n_docker.service_ 에서 ExecStart를 찾아서 --data-root를 추가한다.\n```shell\nsudo vi /usr/lib/systemd/system/docker.service\n```\n```shell\nExecStart=/usr/bin/dockerd --data-root /data/docker -H fd:// ...\n```\n\n## 🔄 재시작\n재시작은 언제나 제일 무서운 타이밍이 아닐까\n\n#### ***서비스 재시작***\n```shell\nsudo systemctl stop docker\nsudo systemctl daemon-reload # docker.service를 수정한 경우에만\nsudo systemctl start docker\n```\nor\n```shell\nsudo systemctl daemon-reload # docker.service를 수정한 경우에만\nsudo systemctl restart docker\n```\n\n#### ***컨테이너 재시작***\n구동중인 프로세스가 있는 경우 컨테이너도 재시작하자.\n\n- 컨테이너 ID 확인\n```shell\ndocker ps\n```\n```shell\n✔\nCONTAINER ID   IMAGE    ...\naaaaaaaaaaaa   ...\nbbbbbbbbbbbb   ...\ncccccccccccc   ...\n```\n\n- 컨테이너 재시작 \n```shell\ndocker restart aaaaaaaaaaaa bbbbbbbbbbbb cccccccccccc\n```\n\n## ✅ 정상 확인\n위 과정들을 마치면 드디어 변경된 Docker Root Directory를 볼 수 있다.\n\n```shell\ndocker info\n```\n```shell\n✔\n...\nDocker Root Dir: /data/docker\n...\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) OpenJDK 17.0.2 PostgreSQL 17.2 SonarQube 9.9 LTA  ✋ 소나큐브란? 소나큐브는 20개 이상의 프로그래밍 언어에서 버그, 코드 스멜, 보안 취약점을 발견할 목적으로 정적 코드 분석으로 자동 리뷰를 수행하기 위한 지속적인 코드 품질 검사용 오픈 소스 플랫폼이다. …","fields":{"slug":"/amazon-linux-sonarqube-install/"},"frontmatter":{"date":"January 20, 2025","title":"Amazon Linux SonarQube 설치","tags":["aws","ec2","amazon-linux","linux","sonarqube"],"emoji":"🔎","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - OpenJDK 17.0.2\n> - PostgreSQL 17.2\n> - SonarQube 9.9 LTA \n\n## ✋ 소나큐브란?\n> 소나큐브는 20개 이상의 프로그래밍 언어에서 버그, 코드 스멜, 보안 취약점을 발견할 목적으로 정적 코드 분석으로 자동 리뷰를 수행하기 위한 지속적인 코드 품질 검사용 오픈 소스 플랫폼이다. 소나소스(SonarSource)가 개발하였다. 소나큐브는 중복 코드, 코딩 표준, 유닛 테스트, 코드 커버리지, 코드 복잡도, 주석, 버그 및 보안 취약점의 보고서를 제공한다.\n> <br/>\n> <br/>\n> 출처 : [위키백과↗](https://ko.wikipedia.org/wiki/소나큐브)\n\n## 📂 PostgreSQL User 및 Database 생성\n\n> ☑️ JDK와 PostgreSQL 등 지원 가능한 데이터베이스의 설치가 선행되어야 한다.\n> <br/>\n> <br/>\n> [PostgreSQL 설치 포스팅 바로가기↗](/amazon-linux-sonarqube-install)\n\n\n#### ***User 생성***\n```sql\nCREATE USER sonar PASSWORD 'sonar';\n```\n\n#### ***Database 생성***\n앞에서 생성한 'sonar' User를 owner로 설정\n```sql\nCREATE DATABASE sonar OWNER sonar;\n```\n\n#### ***권한 설정***\n```sql\nALTER ROLE sonar WITH createdb;\nGRANT ALL PRIVILEGES ON DATABASE sonar TO sonar;\n```\n\n\n## 🚀 SonarQube 다운로드 및 설치\n[소나큐브 다운로드 페이지↗](https://www.sonarsource.com/products/sonarqube/downloads/historical-downloads/)에서 원하는 버전을 다운로드하거나 링크를 복사해둔다.\n\n#### ***다운로드***\n원하는 위치에 다운로드한 파일을 업로드하거나 wget을 이용해서 다운로드 한다. \n```shell\nsudo wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-9.9.8.100196.zip\n```\n\n#### ***압축풀기***\n```shell\nsudo unzip sonarqube-9.9.8.100196.zip\n```\n\n#### ***sonar.properties 수정***\n_설치경로/conf/sonar.properties_\n \n1. 앞에서 설정한 Database의 정보를 입력한다\n2. 웹페이지에서 사용할 포트와 Elastic Search에서 사용할 포트를 수정한다\n   - 기본 포트를 사용해도 무방하고 당연한 말씀이지만 이미 사용중인 포트의 경우에는 오류를 만날 수 있다\n     ```properties\n     sonar.jdbc.username=sonar\n     sonar.jdbc.password=sonar\n     sonar.jdbc.url=jdbc:postgresql://localhost:5432/sonar\n     sonar.web.port=9002\n     sonar.search.port=9003\n     ...\n     ```\n\n#### ***실행***\n_설치경로/bin/linux-x86-64/sonar.sh_\n```shell\n./sonar.sh start\n```\n```shell\n✔\nStarting SonarQube...\nStarted SonarQube.\n```\n\n## ⛔ 예상되는 오류\n생각처럼 실행이 안된다면 _설치경로/logs/es.log_ 파일에서 오류를 확인해보자\n<br/>\n오류를 만나게 되더라도 누구나 겪을 수 있는 일이기 때문에 침착하게 수정하면 된다.\n\n#### ***can not run elasticsearch as root***\n\n#### 오류 내용\n```java\njava.lang.RuntimeException: can not run elasticsearch as root\n        at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:107) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:183) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:434) [elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:166) [elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:157) [elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:77) [elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:112) [elasticsearch-cli-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.Command.main(Command.java:77) [elasticsearch-cli-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:122) [elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:80) [elasticsearch-7.16.2.jar:7.16.2]\n2025.01.02 06:49:40 ERROR es[][o.e.b.ElasticsearchUncaughtExceptionHandler] uncaught exception in thread [main]\norg.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root\n        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:157) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:77) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:112) ~[elasticsearch-cli-7.16.2.jar:7.16.2]\n        at org.elasticsearch.cli.Command.main(Command.java:77) ~[elasticsearch-cli-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:122) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:80) ~[elasticsearch-7.16.2.jar:7.16.2]\nCaused by: java.lang.RuntimeException: can not run elasticsearch as root\n        at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:107) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:183) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:434) ~[elasticsearch-7.16.2.jar:7.16.2]\n        at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:166) ~[elasticsearch-7.16.2.jar:7.16.2]\n        ... 6 more\n```\n\n#### 해결\nelasticsearch는 root 권한으로 실행할 수 없기 때문에 소나큐브의 설치 경로의 소유자를 변경한다.\n<br/>\n필자의 경우 ec2-user를 사용해서 실행했지만 가능하면 소나큐브용 User와 Group을 생성해주자. \n```shell\nsudo chown -R ec2-user:ec2-user 설치경로\n```\n\n#### ***vm.max_map_count***\nElasticsearch를 실행하기 위해서는 vm.max_map_count 값이 최소 262144는 필요하다고 한다.\n\n#### 오류 내용\n```Shell\n[1] bootstrap checks failed. You must address the points described in the following [1] lines before starting Elasticsearch.\nbootstrap check failure [1] of [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n```\n\n#### 해결\n현재 설정된 vm.max_map_count 값을 확인해보자.\n```shell\nsysctl vm.max_map_count\n```\n```shell\n✔\nvm.max_map_count = 65530\n```\nvm.max_map_count 값이 최소 값보다 작게 설정이 되어있기 때문에 다시 설정해주면 해결\n```shell\nsudo sysctl -w vm.max_map_count=262144\n```\n\n## 👋\n다음 포스팅은 Jenkins 파이프라인에서 SonarQube를 활용한 정적 코드 분석을 해봐야겠다.\n\n"},{"excerpt":"☀️ 테스트 환경 AWS S3 Nexus 3.75.1-01 ✋ 들어가며 아직 Nexus가 설치되어있지 않다면 이전 포스팅↗을 확인 \nNexus를 설치했다면 데이터의 저장 위치를 설정해주어야 한다. 기본적으로는 Nexus 설치 위치 하위(sonatype-work/nexus3/blobs)에 구성이 되겠지만 이 포스팅에서는 일반 저장소보다 저렴한 S3를 활용하려…","fields":{"slug":"/nexus-connect-aws-s3/"},"frontmatter":{"date":"January 20, 2025","title":"Nexus에 AWS S3 연결하기 (Blob Stores)","tags":["aws","s3","nexus"],"emoji":"🪣","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - AWS S3\n> - Nexus 3.75.1-01\n\n## ✋ 들어가며\n아직 Nexus가 설치되어있지 않다면 [이전 포스팅↗](/linux-swap-memory)을 확인 <br/>\nNexus를 설치했다면 데이터의 저장 위치를 설정해주어야 한다. 기본적으로는 Nexus 설치 위치 하위(*sonatype-work/nexus3/blobs*)에 구성이 되겠지만 이 포스팅에서는 일반 저장소보다 저렴한 S3를 활용하려고 한다.\n\n\n## 🔑 IAM 권한 사용자 생성 및 액세스 키 발급\n\n이 단계에서는 S3에 Access 할 수 있는 권한 사용자를 생성하고 Nexus 연동을 위한 AccessKey를 발급받는다.\n\n#### ***사용자 생성***\n\n1. 관리 계정으로 로그인 후 `보안 자격 증명` 메뉴 선택\n\n   ![](images/20250106_134503.png)\n\n2. *IAM ➡ 사용자 ➡ 사용자 생성*\n\n   ![](images/20250106_134635.png)\n\n3. 사용자 이름 입력\n\n   ![](images/20250106_134730.png)\n\n4. 권한 옵션은 `직접 정책 연결`로 선택하고 권한 정책에는 `AmazonS3FullAccesss` 정책을 선택한다\n\n   ![](images/20250106_134851.png)\n\n5. 입력 값들은 검토 후 사용자 생성을 완료한다\n\n   ![](images/20250106_134919.png)\n\n#### ***Access Key 발급***\n위 단계에서 S3 접근 권한 사용자를 생성했다면 접근할 수 있는 Access Key를 발급해야한다. <br/>\n이 과정은 AWS Console에서 이루어진다\n\n1. *IAM ➡ 사용자* 에서 생성한 사용자 선택\n\n   ![](images/20250106_134953.png)\n2. 하단 `보안 자격 증명` 탭에서 `액세스 키 만들기`를 선택\n\n   ![](images/20250106_135045.png)\n3. 사용 사례는 `CLI` 선택\n\n   ![](images/20250106_135151.png)\n4. 설명 태그 입력 후 `액세스 키 만들기` 클릭\n\n   ![](images/20250106_135456.png)\n5. 아래 화면과 같이 액세스키가 출력되는데 csv 파일로 다운로드하거나 키를 저장해두어야 한다\n\n   ![](images/20250106_135557.png)\n\n\n## 🔗 Nexus Blob Store에 S3 연결\n사용자 설정이 끝났다면 Nexus 관리자 페이지에서 간단하게 S3 Blob Store를 생성해주자\n\n#### ***Blob Store 생성***\n\n1. 관리계정으로 로그인 후 ⚙️ 화면으로 들어가서 *Blob Stores ➡ Create Blob Store* 클릭\n\n   ![](images/20250106_133114.png)\n2. 당연하게도 필수 입력값인 `Type`을 `S3`로 선택한다\n\n   ![](images/20250106_135703.png)\n3. 생성할 S3의 정보를 입력한다 (Bucket에 입력한 이름으로 S3 Bucket이 생성된다)\n\n   ![](images/20250106_135744.png)\n4. 마지막으로 AWS Console에서 발급받았던 Access Key, Secret Access Key를 입력해준다\n\n   ![](images/20250106_135814.png)\n5. 아래와 같이 생성되었다면 성공\n\n   ![](images/20250106_135853.png)\n\n#### ***S3 Bucket 확인***\n넥서스 관리 페이지에서 입력한 이름의 S3 Bucket이 생성된걸 확인 할 수 있다\n\n   ![](images/20250106_140015.png)\n\n## 👋\nEC2에 마운트되는 SSD등의 스토리지보다 S3가 가격적인 측면에서 큰 차이로 저렴하기 때문에\n서버의 용량 증설을 고려할때 S3도 함께 생각해보면 좋을 것 같다\n"},{"excerpt":"☀️ 테스트 환경 Amazon Linux 2023 (EC2) OpenJDK 17.0.2 Nexus 3.75.1-01 ✋ 넥서스란? Nexus는 Sonartype에서 만든 Repository Manager 솔루션이다. Node 기반의 Package나 Gradle, Maven 기반의 Library 등 다양한 Format의 저장소를 지원한다. 🚀 Nexus 다운…","fields":{"slug":"/amazon-linux-nexus-install/"},"frontmatter":{"date":"January 20, 2025","title":"Amazon Linux에 Nexus 설치하기","tags":["aws","ec2","amazon-linux","linux","nexus"],"emoji":"🔗","series":null},"rawMarkdownBody":"\n\n## ☀️ 테스트 환경\n> - Amazon Linux 2023 (EC2)\n> - OpenJDK 17.0.2\n> - Nexus 3.75.1-01\n\n## ✋ 넥서스란?\nNexus는 Sonartype에서 만든 Repository Manager 솔루션이다. Node 기반의 Package나 Gradle, Maven 기반의 Library 등 다양한 Format의 저장소를 지원한다.\n\n## 🚀 Nexus 다운로드 및 설치\n\n> ☑️ JRE 환경에서 구동되기 때문에 JRE 혹은 JRE가 포함된 JDK의 설치가 필수적이다.\n\n\n[Nexus 다운로드↗](https://help.sonatype.com/en/download-archives---repository-manager-3.html)에서 원하는 버전을 다운로드하거나 링크를 복사해둔다.\n\n#### ***다운로드***\n원하는 위치에 다운로드한 파일을 업로드하거나 wget을 이용해서 다운로드 한다.\n```shell\ncd /nexus\nsudo wget https://download.sonatype.com/nexus/3/nexus-3.75.1-01-unix.tar.gz\n```\n\n#### ***압축풀기***\n```shell\nsudo tar zxvf nexus-3.75.1-01-unix.tar.gz\n```\n\n#### ***계정 생성***\n- 넥서스를 기동할 계정을 생성하고 위에서 압축해제된 폴더 2개의 소유권을 변경한다.\n    ```shell\n    sudo adduser nexus\n    sudo chown -R nexus:nexus /nexus/nexus-3.75.1-01\n    sudo chown -R nexus:nexus /nexus/sonatype-work\n    ```\n\n- nexus.rc 수정\n    ```shell\n    sudo vi /nexus/nexus-3.75.1-01/bin/nexus.rc\n    ```\n    ```vim\n    run_as_user=\"nexus\"\n    ```\n\n- ***서비스 등록***\n    ```shell\n    sudo vi /etc/systemd/system/nexus.service\n    ```\n    ```vim\n    [Unit]\n    Description=nexus service\n    After=network.target\n    \n    [Service]\n    Type=forking\n    LimitNOFILE=65536\n    User=nexus\n    Group=nexus\n    ExecStart=/nexus/nexus-3.75.1-01/bin/nexus start\n    ExecStop=/nexus/nexus-3.75.1-01/bin/nexus stop\n    User=nexus\n    Restart=on-abort\n    \n    [Install]\n    WantedBy=multi-user.target\n    ```\n    ```shell\n    sudo systemctl enable nexus\n    ```\n\n## 💿 실행\n\n#### ***서비스 시작***\n```shell\nsudo systemctl start nexus\n```\n\n#### ***Admin 초기 패스워드 확인***\n```shell\ncat /nexus/sonatype-work/nexus3/admin.password\n```\n```shell\n✔\nXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n```\n\n## 💡 기타\n마지막으로 Nexus가 실행되는 포트를 변경하고 싶다면 아래와 같이 수정하면 된다. (기본 포트는 8081)\n```shell\nsudo vi /nexus/nexus-3.75.1-01/etc/nexus-default.properties\n```\n```vim\n...\napplication-port=9000\n...\n```\n\n## 👋\n\n"},{"excerpt":"☀️ 테스트 환경 AWS Console ✋ 들어가며 파일 업로드/다운로드 기능을 구현할때 지금도 많은 서비스들이 백엔드 프로세스에서 파일을 읽은 후 업로드하거나 다운로드하는 방식을 사용하고 있다.\nObject Storage에 하나인 Amazon S3에 Presigned URL을 통해서 파일을 업로드/다운로드하기 위해서 이 글에서는 Amazon EC2에 S3…","fields":{"slug":"/amazon-ec2-s3-bucket-link/"},"frontmatter":{"date":"January 20, 2025","title":"Amazon EC2에 S3 Bucket 연결 (AWS Console)","tags":["aws","ec2","s3"],"emoji":"🔗","series":"📂 AWS S3 Presigned URL"},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - AWS Console\n\n## ✋ 들어가며\n\n파일 업로드/다운로드 기능을 구현할때 지금도 많은 서비스들이 백엔드 프로세스에서 파일을 읽은 후 업로드하거나 다운로드하는 방식을 사용하고 있다.\nObject Storage에 하나인 Amazon S3에 Presigned URL을 통해서 파일을 업로드/다운로드하기 위해서 이 글에서는 Amazon EC2에 S3 Bucket 접근 권한을 주는 일련의 과정을 설명하려고 한다.\n\n## ❓ Amazon S3(Object Storage)를 선택한 이유\n\n1. 일반적인 File Storage에 비해서 Object Storage를 사용하면 매우 높은 확장성이 보장되며 사용한 만큼만 비용을 지불하기 때문에 초기 비용이 낮다.\n2. Amazon S3에 특정 시간동안만 유효한 Presigned URL을 사용해서 파일에 접근하면 불필요한 접근을 방지할 수 있다.\n3. 데이터 분산 저장으로 저장 데이터 손실에 대한 부담이 매우 낮다.\n\n#### ***Object Storage란?***\n> 오브젝트 스토리지(object storage) 또는 오브젝트 기반 스토리지(object-based storage)는 섹터와 트랙 내에 데이터를 블록으로 관리하는 블록 스토리지, 파일 계층으로서 데이터를 관리하는 파일 시스템과 같은 다른 스토리지 구조와는 반대로 데이터를 오브젝트로 관리하는 기억 장치이다. 각 스토리지는 여러 레벨로 구현될 수 있는데, 여기에는 장치 레벨, 시스템 레벨, 인터페이스 레벨이 있다. 각 케이스에서 오브젝트 스토리지는 다른 스토리지 구조에 의해 언급되지 않는 기능들을 가능케 하려고 노력하는데, 애플리케이션에 의해 직접 프로그래밍 가능한 인터페이스라든지, 물리 하드웨어의 여러 인스턴스를 검색할 수 있는 이름공간이라든지, 데이터 레플리케이션과 같은 데이터 관리 기능이라든지, 오브젝트 레벨의 입도의 데이터 분산을 들 수 있다.\n> <br/><br/>\n> 출처 : [위키백과↗](https://ko.wikipedia.org/wiki/오브젝트_스토리지)\n\n#### ***Object Storage VS File Storage***\n\n| 특성  | Object Storage (S3)          | File Storage                      |\n|-----|------------------------------|-----------------------------------|\n| 구조  | 데이터가 객체로 저장되며, 메타데이터와 함께 관리됨 | 파일 시스템 구조로, 폴더와 파일로 구성됨           |\n| 확장성 | 매우 높은 확장성, 수 페타바이트 이상 저장 가능  | 제한된 확장성, 하드웨어에 따라 다름              |\n| 성능  | 객체 접근 시 지연이 있을 수 있음          | 빠른 접근 속도, 동시 사용량에 따라 서버 부하 가능성 있음 |\n| 내구성 | 높은 내구성, 데이터 복제 및 분산 저장 가능    | 하드웨어 고장 시 데이터 손실 위험이 있음           |\n| 비용  | 사용한 만큼 지불하는 구조로 초기 비용이 낮음    | 초기 투자 비용이 높을 수 있으며, 유지 관리 비용 발생   |\n\n\n## 🛠 AWS Console 설정\nPresigned URL로 파일을 업로드/다운로드하기 위해서는 S3 Bucket은 물론이고 필요에 따라 IAM 정책 및 역할 설정을 해야한다.\n\n#### ***S3 Bucket 생성***\n먼저 가장 중요한 S3 Bucket을 생성해주자.\n\n1. *Amazon S3 ➡ 버킷 만들기*\n\n   ![](images/20250113_163718.png)\n\n2. 파일에 대한 접근은 Presigned URL을 통해서만 이루어질 예정이기 때문에 퍼블릭 엑세스를 차단했다.\n\n   ![](images/20250113_163853.png)\n3. CORS 에러를 방지하기 위해서 접근 가능한 프론트 도메인을 설정했다.\n\n   ![](images/20250115_083503.png)\n\n#### ***IAM 정책 설정***\nS3에 파일을 업로드/다운로드할 수 있는 권한 정책을 생성한다.\n\n1. *IAM ➡ 정책 ➡ 정책 생성*\n\n   ![](images/20250113_164009.png)\n\n2. S3 선택 후 GetObject, GetObjectAcl, PutObject, PutObjectAcl 작업을 허용해준다. (*Acl을 허용하지 않으면 403 에러 발생)\n\n   ![](images/20250113_164352.png)\n\n3. 앞에서 생성한 S3 Bucket 명을 입력하고 모든 하위 Object에 접근 가능하도록 `*` 입력한다.\n\n   ![](images/20250113_164455.png)\n4. 마지막으로 정책 이름을 설정한다.\n\n   ![](images/20250113_164643.png)\n\n#### ***IAM 역할 설정***\n이 단계에서는 위에서 생성한 정책을 EC2 역할로 설정한다.  \n\n1. *IAM ➡ 역할 ➡ 역할 생성*\n\n   ![](images/20250113_164740.png)\n\n2. 엔티티 유형을 AWS 서비스로 선택하고 사용 사례를 EC2로 선택\n\n   ![](images/20250113_164829.png)\n\n3. 위에서 생성한 정책 선택\n\n   ![](images/20250113_164919.png)\n\n4. 역할의 이름을 설정한다.\n\n   ![](images/20250113_165138.png)\n\n5. *EC2 인스턴스 ➡ 작업 ➡ 보안 ➡ IAM 역할 수정*\n\n   ![](images/20250113_165350.png)\n\n6. 위에서 생성한 역할을 선택하면 끝\n\n   ![](images/20250113_165452.png)\n\n\n## 👋\n다음 글에서는 백엔드(Spring Boot)에서 실제로 어떻게 Presigned URL을 생성하고 프론트(React)에서 파일에 접근하는지를 알아봐야겠다.\n"},{"excerpt":"☀️ 테스트 환경 CentOS 8 WSL (Windows 10 Pro) ✋ 들어가며 로컬에서 개발된 소스를 리눅스 환경에 배포할때 메모리에 관련된 에러 메시지를 자주 만날 수 있다. JVM이나 node 환경에서는 Heap memory를 늘려주는 방법으로도 메모리 관련 에러로부터 자유로울 수 있지만, 물리 메모리가 절대적으로 부족한 상황이라면 디스크의 일부분…","fields":{"slug":"/linux-swap-memory/"},"frontmatter":{"date":"January 20, 2025","title":"리눅스 Swap memory 할당/해제","tags":["linux","swap-memory"],"emoji":"💿","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - CentOS 8\n> - WSL (Windows 10 Pro)\n\n## ✋ 들어가며\n로컬에서 개발된 소스를 리눅스 환경에 배포할때 메모리에 관련된 에러 메시지를 자주 만날 수 있다. JVM이나 node 환경에서는 Heap memory를 늘려주는 방법으로도 메모리 관련 에러로부터 자유로울 수 있지만, 물리 메모리가 절대적으로 부족한 상황이라면 디스크의 일부분을 메모리처럼 활용할 수 있는 Swap memory 설정이 해결책이 될 수 있다.\n\n#### ***Swap Memory란?***\n메모리가 가든찬 경우에도 디스크의 일부분을 활용하여 메모리를 대체할 수 있도록 할당한 공간이다.\n\n#### ***Swap Memory의 권장 크기***\n[Red Hat Enterprise Linux 권장 Swap 크기↗](https://access.redhat.com/ko/solutions/744483)를 참고하면 Swap 공간을 얼마나 할당해서 사용해야 할지에 대한 답을 찾을 수 있지만 디스크의 일부분을 사용하기 때문에 여유 디스크의 사이즈도 고려해서 할당해야 한다.\n\n\n## ✅ Swap Memory 할당\n\n#### ***메모리 확인***\n할당 전 메모리를 확인해보면 Swap 영역이 '0B'로 잡혀있는 것을 확인 할 수 있다.\n```shell\nfree -h\n```\n```shell\n✔\n              total        used        free      shared  buff/cache   available\nMem:            15G          0B          0B          0B          0B          0B\nSwap:            0B          0B          0B\n```\n\n#### ***Swap File 생성 및 권한 설정***\n할당할 용량의 파일을 루트 경로에 생성하고 권한을 설정한다.\n```shell\nfallocate -l 8G /swapfile\nchmod 600 /swapfile\ncd /\nls -alh\n```\n```shell\n✔\ndr-xr-xr-x  22 root    root     314 Dec  5 04:53 .\ndr-xr-xr-x  22 root    root     314 Dec  5 04:53 ..\n-rw-------   1 root    root    8.0G Dec  5 05:45 swapfile\n```\n\n#### ***Swap 파티션 생성 및 활성화***\n\n1. 스왑 파티션 생성\n- 재기동 후에도 파티션이 유지되도록 설정하기 위해서 출력되는 UUID는 복사해둔다. \n    \n    ```shell\n    mkswap /swapfile\n    ```\n    ```shell\n    ✔\n    Setting up swapspace version 1, size = 8 GiB (8589934592 bytes)\n    no label, UUID=XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n    ```\n\n2. 스왑 영역 활성화 및 확인\n    ```shell\n    swapon /swapfile\n    free -h\n    ```\n    ```shell\n    ✔\n                  total        used        free      shared  buff/cache   available\n    Mem:            15G          0B          0B          0B          0B          0B\n    Swap:            8G          0B          0B\n    ```\n\n3. fstab에 파티션 추가\n   - 복사해두었던 UUID를 Tab 문자열이나 공백으로 구분해서 '/etc/fstab' 하단에 작성하면 재기동 후에도 유지된다.\n    ```shell\n    vi /etc/fstab\n    ```\n    ```shell\n    ✔\n    ...\n    UUID=XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX swap swap defaults 0 0\n    ```\n\n\n## ❎ Swap Memory 해제\n\n#### ***Swap 영역 비활성화***\n스왑을 비활성화 해주고 생성했던 '/swapfile'을 삭제하면 다시 '0B'로 변한걸 확인할 수 있다.\n```shell\nswapoff /swapfile\nrm -rf /swapfile\nfree -h\n```\n```shell\n✔\n              total        used        free      shared  buff/cache   available\nMem:            15G          0B          0B          0B          0B          0B\nSwap:            0B          0B          0B\n```\n\n#### ***fstab 파티션 삭제***\n추가했던 UUID를 제거하면 Swap Memory 해제가 완료된다. \n```shell\nvi /etc/fstab\n```\n\n\n## 👋 마치며\nWindows 10 Pro 환경에서 WSL을 활성화하고 CentOS 8을 설치해봤는데 생각보다 안정적이지 못한 느낌이 든다. 연습장으로 사용할 다른 대안을 찾아봐야겠다.\n\n"},{"excerpt":"☀️ 테스트 환경 IntelliJ IDEA 2024.3 (Ultimate Edition) PostgreSQL 16.1 (Amazon Aurora) ✋ 들어가며 데이터베이스에 생성되어있는 테이블을 기반으로 VO(DTO)를 생성하고 매번 작성해야하는 Mybatis 기반의 쿼리를 자동으로 생성할 수 없을까? 고민하는 중에 인텔리제이와 약간의 Groovy 기반의 …","fields":{"slug":"/intellij-vo-mybatis-xml/"},"frontmatter":{"date":"January 19, 2025","title":"VO 및 Mybatis XML 자동 생성하기 (with. IntelliJ)","tags":["intellij"],"emoji":"🚘","series":null},"rawMarkdownBody":"\n## ☀️ 테스트 환경\n> - IntelliJ IDEA 2024.3 (Ultimate Edition)\n>\n> - PostgreSQL 16.1 (Amazon Aurora)\n\n## ✋ 들어가며\n데이터베이스에 생성되어있는 테이블을 기반으로 VO(DTO)를 생성하고 매번 작성해야하는 Mybatis 기반의 쿼리를 자동으로 생성할 수 없을까?\n\n고민하는 중에 인텔리제이와 약간의 Groovy 기반의 코딩을 이용하는 좋은 방법이 생겼다. 테스트 환경은 Ultimate Edition이지만 Community Edition도 가능하다.\n\n## 💾 Database 설정 및 연결\n\n#### ***Database ➡ <shortcut> + </shortcut> ➡ Data Source ➡ PostgreSQL*** \n- 테스트 환경은 PostgreSQL이지만 지원하는 Data Source라면 모두 사용 가능하다.\n\n   ![](images/20241205_100506.png)\n\n#### ***PostgreSQL 연결***\n1. PostgreSQL의 Host, User 등 접속 정보를 입력하고 OK 버튼을 클릭한다.\n\n   ![](images/20241205_101046.png)\n\n2. 연결되면 Database 탭에서 테이블 정보를 확인 할 수 있다.\n\n   ![](images/20241205_101236.png)\n\n## 📝 Groovy Script 작성\n\n#### ***스크립트 파일 생성***\n1. 데이터베이스 연결이 완료되면 Project 탭에서 아래와 같은 내용을 확인 할 수 있다.\n2. _Generate POJOs.groovy_ 파일을 복사해서 새로운 이름으로 만들어준다.\n\n   ![](images/20241205_101358.png)\n\n#### ***스크립트 수정***\n1. VO 파일에 _lombok_, _Swagger_ 등을 적용하기 위해서 기본 파일을 수정 했다.\n2. 그리고 Mybatis 기반의 XML 쿼리까지 생성해주길 원하기 때문에 해당 부분을 추가 작성. \n3. 소스 전문\n   ```groovy\n   import com.intellij.database.model.DasTable\n   import com.intellij.database.util.Case\n   import com.intellij.database.util.DasUtil\n   \n   /*\n    * Available context bindings:\n    *   SELECTION   Iterable<DasObject>\n    *   PROJECT     project\n    *   FILES       files helper\n    */\n   packageName = \"_packageName_;\"\n   typeMapping = [\n           (~/(?i)int/)                      : \"int\",\n           (~/(?i)float|double|decimal|real/): \"double\",\n           (~/(?i)datetime|timestamp/)       : \"String\",\n           (~/(?i)date/)                     : \"String\",\n           (~/(?i)time/)                     : \"String\",\n           (~/(?i)/)                         : \"String\"\n   ]\n   \n   FILES.chooseDirectoryAndSave(\"Choose directory\", \"Choose where to store generated files\") { dir ->\n       SELECTION.filter { it instanceof DasTable }.each { generateVo(it, dir) }\n       SELECTION.filter { it instanceof DasTable }.each { generateSql(it, dir) }\n   }\n   \n   def generateVo(table, dir) {\n       def className = javaName(table.getName(), true)\n       def fields = calcFields(table)\n       def folderName = \"${dir}/model\"\n       def folder = new File(folderName)\n       if (!folder.exists()) {\n           folder.mkdirs()\n       }\n       new File(folderName, className + \".java\").withPrintWriter { out -> generateVo(out, className, fields) }\n   }\n   \n   def generateSql(table, dir) {\n       def camelClassName = javaName(table.getName(), true)\n       def className = table.getName()\n       def fields = calcFields(table)\n       def folderName = \"${dir}/sql\"\n       def folder = new File(folderName)\n       if (!folder.exists()) {\n           folder.mkdirs()\n       }\n       new File(folder, className + \".xml\").withPrintWriter { out -> generateSql(out, camelClassName, className, fields) }\n   }\n   \n   def generateVo(out, className, fields) {\n       out.println \"package $packageName\"\n       out.println \"\"\n       out.println \"import lombok.*;\"\n       out.println \"import com.fasterxml.jackson.annotation.JsonInclude;\"\n       out.println \"import io.swagger.v3.oas.annotations.media.Schema;\"\n       out.println \"\"\n       out.println \"@AllArgsConstructor(access = AccessLevel.PRIVATE)\"\n       out.println \"@NoArgsConstructor\"\n       out.println \"@Data\"\n       out.println \"@Builder\"\n       out.println \"@JsonInclude(JsonInclude.Include.NON_NULL)\"\n       out.println \"public class $className {\"\n       out.println \"\"\n       fields.each() {\n           if (it.annos != \"\") out.println \"  ${it.annos}\"\n           out.println \"\\t@Schema(description = \\\"${it.comment}\\\", example = \\\"${it.comment}\\\")\"\n           out.println \"\\tprivate ${it.type} ${it.camelName};\"\n           out.println \"\"\n       }\n       out.println \"}\"\n   }\n   \n   def generateSql(out, camelClassName, className, fields) {\n       out.println '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n       out.println '<!DOCTYPE mapper'\n       out.println '\\t\\tPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"'\n       out.println '\\t\\t\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">'\n       out.println \"<mapper namespace=\\\"_namespace_\\\">\"\n   \n       out.println \"\"\n       out.println \"\\t<select id=\\\"select${camelClassName}\\\" parameterType=\\\"\\\" resultType=\\\"\\\">\"\n       out.println \"\\t\\t/* Query ID : _namespace_.select${camelClassName} */\"\n       out.println \"\\t\\tSELECT \"\n       def index = 0;\n   \n       fields.each() {\n           if (index != 0) {\n               out.println \"\\t\\t\\t,${Case.UPPER.apply(it.name)}\"\n           } else {\n               index = 1;\n               out.println \"\\t\\t\\t${Case.UPPER.apply(it.name)}\"\n           }\n       }\n       out.println \"\\t\\tFROM ${Case.UPPER.apply(className)}\"\n       out.println \"\\t\\tWHERE 1=1\"\n       out.println \"\\t</select>\"\n   \n   \n       out.println \"\"\n       out.println \"\\t<insert id=\\\"insert${camelClassName}\\\" parameterType=\\\"\\\">\"\n       out.println \"\\t\\t/* Query ID : _namespace_.insert${camelClassName} */\"\n       out.println \"\\t\\tINSERT INTO ${Case.UPPER.apply(className)} (\"\n       index = 0;\n       fields.each() {\n           if (index != 0) {\n               out.println \"\\t\\t\\t,${Case.UPPER.apply(it.name)}\"\n           } else {\n               index = 1;\n               out.println \"\\t\\t\\t${Case.UPPER.apply(it.name)}\"\n           }\n       }\n       out.println \"\\t\\t) VALUES (\"\n       index = 0;\n       fields.each() {\n           if (index != 0) {\n               out.println \"\\t\\t\\t,#{${it.camelName}}\"\n           } else {\n               index = 1;\n               out.println \"\\t\\t\\t#{${it.camelName}}\"\n           }\n       }\n       out.println \"\\t\\t)\"\n       out.println \"\\t</insert>\"\n   \n       out.println \"\"\n       out.println \"\\t<update id=\\\"update${camelClassName}\\\" parameterType=\\\"\\\">\"\n       out.println \"\\t\\t/* Query ID : _namespace_.update${camelClassName} */\"\n       out.println \"\\t\\tUPDATE ${Case.UPPER.apply(className)} SET \"\n       index = 0;\n   \n       fields.each() {\n           if (index != 0) {\n               out.println \"\\t\\t\\t,${Case.UPPER.apply(it.name)} = #{${it.camelName}}\"\n           } else {\n               index = 1;\n               out.println \"\\t\\t\\t${Case.UPPER.apply(it.name)} = #{${it.camelName}}\"\n           }\n       }\n       out.println \"\\t\\tWHERE 1=1\"\n       out.println \"\\t</update>\"\n   \n   \n       out.println '</mapper>'\n   }\n   \n   def calcFields(table) {\n       DasUtil.getColumns(table).reduce([]) { fields, col ->\n           def spec = Case.LOWER.apply(col.getDasType().getSpecification())\n           def typeStr = typeMapping.find { p, t -> p.matcher(spec).find() }.value\n           fields += [[\n                              camelName: javaName(col.getName(), false),\n                              name     : col.getName(),\n                              type     : typeStr,\n                              comment  : col.getComment(),\n                              annos    : \"\"]]\n       }\n   }\n   \n   def javaName(str, capitalize) {\n       def s = com.intellij.psi.codeStyle.NameUtil.splitNameIntoWords(str)\n               .collect { Case.LOWER.apply(it).capitalize() }\n               .join(\"\")\n               .replaceAll(/[^\\p{javaJavaIdentifierPart}[_]]/, \"_\")\n       capitalize || s.length() == 1 ? s : Case.LOWER.apply(s[0]) + s[1..-1]\n   }\n   ```\n\n## 💿 실행 및 결과\n\n#### ***실행*** \n1. *Database ➡ tables ➡ Tools ➡ Scripted Extensions ➡ 생성한 Groovy 파일*\n2. 저장할 위치 선택\n\n   ![](images/20241205_101601.png)\n\n#### ***결과***\n1. 선택된 위치에 model, sql 폴더가 각각 생성된다.\n\n   ![](images/20241205_101701.png)\n\n2. 생성된 파일 예시\n   - VO (TbSample.java)\n     ```java\n         package _packageName_;\n        \n         import lombok.*;\n         import com.fasterxml.jackson.annotation.JsonInclude;\n         import io.swagger.v3.oas.annotations.media.Schema;\n        \n         @AllArgsConstructor(access = AccessLevel.PRIVATE)\n         @NoArgsConstructor\n         @Data\n         @Builder\n         @JsonInclude(JsonInclude.Include.NON_NULL)\n         public class TbSample {\n        \n             @Schema(description = \"Column 1\", example = \"Column 1\")\n             private String colOne;\n        \n             @Schema(description = \"Column 2\", example = \"Column 2\")\n             private String colTwo;\n        \n             @Schema(description = \"Column 3\", example = \"Column 3\")\n             private String colThree;\n         }   \n     ```\n   - Mybatis XML Mapper (tb_sample.xml)\n     ```xml\n     <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n     <!DOCTYPE mapper\n            PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n            \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n     <mapper namespace=\"_namespace_\">\n    \n        <select id=\"selectTbSample\" parameterType=\"\" resultType=\"\">\n            /* Query ID : _namespace_.selectTbSample */\n            SELECT \n                COL_ONE\n                ,COL_TWO\n                ,COL_THREE\n            FROM TB_SAMPLE\n            WHERE 1=1\n        </select>\n    \n        <insert id=\"insertTbSample\" parameterType=\"\">\n            /* Query ID : _namespace_.insertTbSample */\n            INSERT INTO TB_SAMPLE (\n                COL_ONE\n                ,COL_TWO\n                ,COL_THREE\n            ) VALUES (\n                #{colOne}\n                ,#{colTwo}\n                ,#{colThree}\n            )\n        </insert>\n    \n        <update id=\"updateTbSample\" parameterType=\"\">\n            /* Query ID : _namespace_.updateTbSample */\n            UPDATE TB_SAMPLE SET \n                COL_ONE = #{colOne}\n                ,COL_TWO = #{colTwo}\n                ,COL_THREE = #{colThree}\n            WHERE 1=1\n        </update>\n     </mapper>\n     ```\n   \n## 👋 마치며\n역시 _Jetbrains_ 은 최고.. _IntelliJ_ 를 사용하지 않을 수 없다. (~~학생계정으로 써서 미안~~)\n\n"},{"excerpt":"안내 ⚠️ 현재 'Writerside'를 사용하지 않고 있습니다. ☀️ 사전 준비 ttf 확장자를 가진 폰트 파일 (현재 페이지에서는 네이버에서 만든 D2Coding↗을 사용) ✏️ StyleSheet 디렉토리 생성 Writerside/cfg/static 경로에 준비한 글꼴 파일을 옮기고 CSS 파일을 생성한다.  CSS 작성 font-face를 설정하고 모든…","fields":{"slug":"/writerside-font-change-d2coding/"},"frontmatter":{"date":"January 10, 2025","title":"Writerside Font 변경하기 (feat. D2Coding)","tags":["github-pages","blog","writerside"],"emoji":"💬","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n## 안내\n> ⚠️ 현재 'Writerside'를 사용하지 않고 있습니다.\n\n\n## ☀️ ***사전 준비***\n> ttf 확장자를 가진 폰트 파일 (현재 페이지에서는 네이버에서 만든 [D2Coding↗](https://github.com/naver/d2codingfont)을 사용)\n\n## ✏️ StyleSheet\n\n#### ***디렉토리 생성***\n- _Writerside/cfg/static_ 경로에 준비한 글꼴 파일을 옮기고 CSS 파일을 생성한다.\n\n   ![](images/20241209_132048.png)\n\n#### ***CSS 작성***\n- font-face를 설정하고 모든 elements 영역의 글꼴을 d2coding으로 설정.\n  ```css\n  @font-face {\n      font-family: d2coding;\n      src: url('D2Coding-Ver1.3.2-20180524.ttf');\n  }\n  * {\n      font-family: d2coding !important;\n  }\n  ```\n\n## 🛠️ Writerside buildprofiles 설정\n\n#### ***Writerside/cfg/buildprofiles.xml***\n- *buildprofiles ➡ variables ➡ custom-css* 영역에 생성한 CSS 파일명을 입력한다.\n  ```xml\n  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  <buildprofiles xsi:noNamespaceSchemaLocation=\"https://resources.jetbrains.com/writerside/1.0/build-profiles.xsd\"\n                 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n      <variables>\n          <custom-css>custom.css</custom-css>\n      </variables>\n      <build-profile instance=\"in\">\n          <variables>\n              <noindex-content>false</noindex-content>\n          </variables>\n      </build-profile>\n      <footer>\n          <link href=\"https://github.com/rundevelrun\">GitHub</link>\n          <copyright>2024. RUN:DEVEL:RUN All Rights Reserved.</copyright>\n      </footer>\n      <sitemap priority=\"0.35\" change-frequency=\"daily\"/>\n  </buildprofiles>\n  ```\n\n## 👋 마치며\nD2Coding을 사용하면 개발을 하면서 구분하지 못하는 문자가 없어져서 좋은데 개발 블로그를 운영할때도 좋은 것 같다.\n\n"},{"excerpt":"안내 ⚠️ 현재 'Writerside'를 사용하지 않고 있습니다. ☀️ 사전 준비 Github Page 생성 (Github Pages 시작하기↗) Writerside↗ 문서 작성자를 위해, 문서 작성자가 만들었다는 Jetbrains의 문서 작성 도구 필자는 Jetbrains의 신봉자로서 Writerside를 이용해서 현재 페이지를 운영중이다. 📝 Github…","fields":{"slug":"/writerside-deploy-on-github/"},"frontmatter":{"date":"January 10, 2025","title":"Writerside Github에 배포하기","tags":["github-pages","blog","writerside"],"emoji":"🛫","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n## 안내\n> ⚠️ 현재 'Writerside'를 사용하지 않고 있습니다.\n\n## ☀️ ***사전 준비***\n> 1. Github Page 생성 ([Github Pages 시작하기↗](https://6developer.com/github-pages-start.html))\n> 2. [Writerside↗](https://www.jetbrains.com/ko-kr/writerside/)\n>  - 문서 작성자를 위해, 문서 작성자가 만들었다는 Jetbrains의 문서 작성 도구\n>  - 필자는 Jetbrains의 신봉자로서 Writerside를 이용해서 현재 페이지를 운영중이다.\n>  - \n\n## 📝 Github Actions Workflows 작성\nGithub Pages에 정적 페이지를 빌드 후 배포하기 위해서는 Jenkins의 Pipeline과 같은 역할을 하는 Github Actions을 사용한다.\n\n#### ***Workflows 파일 생성***\n- _.github/workflows_ 아래 _build-docs.yml_ 파일을 생성한다.\n\n   ![](images/20241205_163053.png)\n\n#### ***Workflows 작성***\n- [공식 문서↗](https://www.jetbrains.com/help/writerside/deploy-docs-to-github-pages.html#build)를 보고 필요한 부분을 추리고 수정해서 아래와 같은 소스를 완성 했다.\n- Job은 간단하게 Build, Deploy로 구성했다.\n    ```yaml\n    name: Build documentation\n    \n    on:\n      push:\n        branches: [ \"main\" ]\n      workflow_dispatch:\n    \n    permissions:\n      id-token: write\n      pages: write\n    \n    env:\n      INSTANCE: 'Writerside/in'\n      ARTIFACT: 'webHelpIN2-all.zip'\n      DOCKER_VERSION: '241.15989'\n    \n    jobs:\n      build:\n        runs-on: ubuntu-latest\n        steps:\n          - name: Checkout repository\n            uses: actions/checkout@v4\n            with:\n              fetch-depth: 0\n    \n          - name: Build docs using Writerside Docker builder\n            uses: JetBrains/writerside-github-action@v4\n            with:\n              instance: ${{ env.INSTANCE }}\n              artifact: ${{ env.ARTIFACT }}\n              docker-version: ${{ env.DOCKER_VERSION }}\n    \n          - name: Save artifact with build results\n            uses: actions/upload-artifact@v4\n            with:\n              name: docs\n              path: |\n                artifacts/${{ env.ARTIFACT }}\n                artifacts/report.json\n              retention-days: 7\n      deploy:\n        environment:\n          name: github-pages\n          url: ${{ steps.deployment.outputs.page_url }}\n        needs: [ build ]\n        runs-on: ubuntu-latest\n        steps:\n          - name: Download artifacts\n            uses: actions/download-artifact@v4\n            with:\n              name: docs\n    \n          - name: Unzip artifact\n            run: unzip -O UTF-8 -qq '${{ env.ARTIFACT }}' -d dir\n    \n          - name: Setup Pages\n            uses: actions/configure-pages@v4\n    \n          - name: Package and upload Pages artifact\n            uses: actions/upload-pages-artifact@v3\n            with:\n              path: dir\n    \n          - name: Deploy to GitHub Pages\n            id: deployment\n            uses: actions/deploy-pages@v4\n    ```\n\n## 🚀 빌드 및 배포\n\n#### ***배포 대상 브랜치 병합***\n- 위 소스를 그대로 사용하면 'main' branch에 변화(push or merge)가 생기면 빌드 및 배포가 실행된다.\n- 대상 브랜치를 변경하고 싶으면 소스의 아래 부분을 수정한다.\n```yaml\n...\non:\n  push:\n    branches: [ \"main\" ]  # 대상 브랜치 \n  workflow_dispatch:\n...\n```\n\n#### ***확인***\n- *Actions ➡ Build Number*\n- Github Page를 운영중인 Repository에서 배포 상태를 확인 할 수 있다.\n\n   ![](images/20241205_165648.png)\n\n## 👋 마치며\n지금 보고 있는 이 사이트의 모든 소스는 [여기↗](https://github.com/rundevelrun/rundevelrun.github.io)에서 확인이 가능하다.\n\n"},{"excerpt":"🔈 도메인 준비 ☀️ 당연한 말씀\n\nGithub Pages에 사용자 정의 도메인을 설정하려면 개인 도메인이 준비되어있어야 한다.\n(개인 도메인은 가비아, 후이즈 등 각종 호스팅 사이트에서 구매가능하며 원하는 사이트를 통해서 구매) 💎 DNS 레코드 설정 사용 가능한 DNS 레코드의 종류는 여기↗에서 확인이 가능하며 필자의 경우 A 레코드를 사용했다. A 레…","fields":{"slug":"/github-pages-personal-domain/"},"frontmatter":{"date":"January 10, 2025","title":"Github Pages 사용자 정의 도메인 설정","tags":["github-pages","blog","domain"],"emoji":"🚀","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n## 🔈 도메인 준비\n\n> ☀️ ***당연한 말씀***\n> <br/><br/>\n> Github Pages에 사용자 정의 도메인을 설정하려면 개인 도메인이 준비되어있어야 한다.\n> (개인 도메인은 가비아, 후이즈 등 각종 호스팅 사이트에서 구매가능하며 원하는 사이트를 통해서 구매)\n\n## 💎 DNS 레코드 설정\n사용 가능한 DNS 레코드의 종류는 [여기↗](https://docs.github.com/ko/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#dns-records-for-your-custom-domain)에서 확인이 가능하며 필자의 경우 A 레코드를 사용했다.\n\n#### ***A 레코드 추가***\n1. 호스팅 사이트마다 사용하는 방식은 다를 수 있지만 아래와 같이 4종류의 레코드를 등록한다.\n2. 필자는 A 레코드를 사용했지만 기호에 맞게 등록하기로 한다.\n\n   ![](images/20241125_083158.png)\n\n## 🍨 Github 도메인 등록\nGithub Pages를 운영중인 Repository에 도메인을 등록한다.\n\n#### ***도메인 등록***\n*Settings ➡ Pages ➡ Custom domain*\n- DNS 레코드 설정을 마친 도메인을 입력한다.\n\n    ![](images/20241125_082905.png)\n\n#### ***Enforce HTTPS 설정***\n1. 도메인 등록이 완료되면 **약 15분 후** 체크박스가 활성화 된다.\n2. 항상 https로 접속하기 위해서 **Enforce HTTPS**에 꼭 체크해주자.\n\n   ![](images/20241125_083307.png)\n\n#### ***접속 확인***\n1. 등록한 도메인으로 접속하면 ~~*.github.io~~ 대신 도메인으로 접속이 되는걸 확인할 수 있다.\n2. ~~*.github.io~~ 접속시 등록한 도메인으로 redirect 된다.\n\n   ![](images/20241125_134247.png)\n\n## 👋 마치며\nJetbrains 신봉자인 내 눈 앞에 나타난 [Writerside↗](https://www.jetbrains.com/ko-kr/writerside/)로 기술블로그를 시작했다.\n티스토리, 네이버 블로그, 벨로그를 거쳐서 Jekyll 테마를 활용한 Github Pages까지 운영을 해봤지만 드디어 똥손이 운영하기에 가장 적합한 도구를 찾은 것 같다.\n"},{"excerpt":"🔈 Github 계정 준비 ☀️ 당연한 말씀\n\nGithub page를 이용해서 개인 홈페이지나 블로그를 운영하기 위해서는\nGithub↗에 가입된 계정이 있어야 한다. 💎 Repository 생성 자신의 깃허브 계정에서 개인 사이트를 운영할 레파지토리를 생성한다. 생성 메뉴 접속 Profile ➡ Your repositories ➡ New  정보 입력 및 생…","fields":{"slug":"/github-pages-start/"},"frontmatter":{"date":"January 10, 2025","title":"Github Pages 시작하기","tags":["github-pages","blog"],"emoji":"👋","series":"📝 나만의 블로그를 운영하며"},"rawMarkdownBody":"\n\n## 🔈 Github 계정 준비\n\n> ☀️ ***당연한 말씀***\n> <br/><br/>\n> Github page를 이용해서 개인 홈페이지나 블로그를 운영하기 위해서는\n> [Github↗](https://github.com/)에 가입된 계정이 있어야 한다.\n\n## 💎 Repository 생성\n자신의 깃허브 계정에서 개인 사이트를 운영할 레파지토리를 생성한다.\n\n#### ***생성 메뉴 접속***\n*Profile ➡ Your repositories ➡ New*\n\n![](images/20241127_172942.png)\n\n#### ***정보 입력 및 생성***\n1. Repository name\n    - <shortcut>계정ID.github.io</shortcut> 입력시 `https://계정ID.github.io`로 접속\n    - 그 외 <shortcut>xxxxx</shortcut> 입력시 [사용자 정의 도메인 설정](https://6developer.com/github-pages-personal-domain.html) 필요\n2. Add a README file 체크\n   - *README.md*의 내용이 초기 화면으로 표시\n   \n      ![](images/20241127_164354.png)\n\n#### ***빌드 및 배포 설정***\n*Settings ➡ Pages*\n1. *Build and deployment*의 설정을 `GitHub Actions`로 변경\n2. 보고 있는 페이지는 *GitHub Action*을 이용해서 빌드와 배포가 이루어지는데 해당 내용을 포스팅 할 예정\n\n![](images/20241128_083031.png)\n\n#### ***접속 확인***\n*Settings ➡ Pages*\n1. 자신의 접속 도메인은 설정 페이지에서 확인하고 접속할 수 있다.\n2. `https://계정ID.github.io` 혹은 사용자 정의 도메인으로 접속\n\n![](images/20241128_083702.png)\n\n## 👋 마치며\nWriterside를 이용해서 포스팅을 이어가고 있는데 아직 카테고리 구성이나 상위메뉴, 메인페이지 등을 어떻게 구성할지 감이 안잡힌다.\n하나씩 보완해가면서 구성해야겠다.\n\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}